{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21316,
     "status": "ok",
     "timestamp": 1764570567099,
     "user": {
      "displayName": "주식회사한시경",
      "userId": "01036671795204052858"
     },
     "user_tz": -540
    },
    "id": "1VCkYZJamUXD",
    "outputId": "537d34df-01ac-4365-c6b2-7430b8f7662f"
   },
   "outputs": [],
   "source": [
    "# 나눔고딕 폰트 설치\n",
    "!apt-get update -qq\n",
    "!apt-get install -y fonts-nanum\n",
    "\n",
    "# Matplotlib 폰트 설정\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib\n",
    "\n",
    "# 나눔고딕 폰트 경로 설정\n",
    "font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "rc('font', family='NanumGothic', size=12)\n",
    "\n",
    "# 마이너스 폰트 깨짐 방지\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"폰트 설정 완료 - NanumGothic 적용됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1764570583040,
     "user": {
      "displayName": "주식회사한시경",
      "userId": "01036671795204052858"
     },
     "user_tz": -540
    },
    "id": "_CLdWv6umkTS",
    "outputId": "05224da5-3575-4208-c651-db0bfde5dcc7"
   },
   "outputs": [],
   "source": [
    "# ===== 테스트 그래프 =====\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"그래프 한글 테스트\")\n",
    "plt.plot([1,2,3],[1,4,9])\n",
    "plt.xlabel(\"입력 데이터\")\n",
    "plt.ylabel(\"출력 결과\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1764570606146,
     "user": {
      "displayName": "주식회사한시경",
      "userId": "01036671795204052858"
     },
     "user_tz": -540
    },
    "id": "s-eP6_g3mlks"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wib56U37mpxL"
   },
   "outputs": [],
   "source": [
    "# U-Net 생성자(Generator) 클래스 정의\n",
    "class UNetGenerator(nn.Module):\n",
    "  def __init__(self, chnls_in=3, chnls_op=3):\n",
    "    super(UNetGenerator, self).__init__()\n",
    "    # 인코더(downsampling) 블록 >> 특징추출\n",
    "    self.down_conv_layer1 = DownConvBlock(chnls_in, 64, norm=False)\n",
    "    self.down_conv_layer2 = DownConvBlock(64, 128)\n",
    "    self.down_conv_layer3 = DownConvBlock(128, 256)\n",
    "    # 깊은 레이어는 드롭아웃 적용하여 과적합 방지\n",
    "    self.down_conv_layer4 = DownConvBlock(256, 512, dropout=0.5)\n",
    "    self.down_conv_layer5 = DownConvBlock(512, 512, dropout=0.5)\n",
    "    self.down_conv_layer6 = DownConvBlock(512, 512, dropout=0.5)\n",
    "    self.down_conv_layer7 = DownConvBlock(512, 512, dropout=0.5)\n",
    "    # 병목(bottle-neck)부분 : 해상도 변경없음, 정규화, 드롭아웃 비활성화/활성화 옵션적용\n",
    "    self.down_conv_layer8 = DownConvBlock(512, 512, dropout=0.5)\n",
    "    \n",
    "    # 디코더(upsampling) 블록 >> 특징복원\n",
    "    # skip-connection 통해 인코더 출력받음\n",
    "    # UpConvBlock의 입력채널(이전 디코더의 출력채널 + 해당 인코더 출력채널)\n",
    "    # enc8 + enc7 (512+512) 를 받아서 512채널로 복원\n",
    "    self.up_conv_layer1 = nn.UpConvBlock(512, 512, dropout=0.5)\n",
    "    # enc7 + enc6 (512+512) 를 받아서 512채널로 복원\n",
    "    self.up_conv_layer2 = nn.UpConvBlock(1024, 512, dropout=0.5)\n",
    "    self.up_conv_layer3 = nn.UpConvBlock(1024, 512, dropout=0.5)\n",
    "    self.up_conv_layer4 = nn.UpConvBlock(1024, 512, dropout=0.5)\n",
    "    self.up_conv_layer5 = nn.UpConvBlock(1024, 256)\n",
    "    self.up_conv_layer6 = nn.UpConvBlock(512, 128)\n",
    "    self.up_conv_layer7 = nn.UpConvBlock(256, 64)\n",
    "\n",
    "    # 최종출력 레이어 정의\n",
    "    self.upsample_layer = nn.Upsample(scale_factor=2)\n",
    "    # 패딩 위한 레이어 정의\n",
    "    # nn.ZeroPad2d((left, right, top, down))\n",
    "    self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
    "\n",
    "    # [128, 3, 4, 1]\n",
    "    self.conv_layer1 = nn.Conv2d(128, chnls_op, 4, padding=1)\n",
    "    # 출력 픽셀값 범위 제한 [-1, 1]\n",
    "    self.activation = nn.Tanh()\n",
    "\n",
    "    # 순전파 정의\n",
    "  def forward(self, x):\n",
    "    # 인코딩 경로\n",
    "    enc1 = self.down_conv_layer1(x)\n",
    "    enc2 = self.down_conv_layer2(enc1)\n",
    "    enc3 = self.down_conv_layer3(enc2)\n",
    "    enc4 = self.down_conv_layer4(enc3)\n",
    "    enc5 = self.down_conv_layer5(enc4)\n",
    "    enc6 = self.down_conv_layer6(enc5)\n",
    "    enc7 = self.down_conv_layer7(enc6)\n",
    "    enc8 = self.down_conv_layer8(enc7)  # 병목(bottle-neck) 부분\n",
    "\n",
    "    # 디코딩 경로\n",
    "    # denX + encY\n",
    "    dec1 = self.up_conv_layer1(enc8, enc7)\n",
    "    dec2 = self.up_conv_layer2(dec1, enc6)\n",
    "    dec3 = self.up_conv_layer2(dec2, enc5)\n",
    "    dec4 = self.up_conv_layer2(dec3, enc4)\n",
    "    dec5 = self.up_conv_layer2(dec4, enc3)\n",
    "    dec6 = self.up_conv_layer2(dec5, enc2)\n",
    "    dec7 = self.up_conv_layer2(dec6, enc1)    \n",
    "    \n",
    "    final = self.upsample_layer(dec7)\n",
    "\n",
    "    # 최종 합성곱을 위한 패딩 적용\n",
    "    final = self.zero_pad(final)\n",
    "    # 최종 합성곱 레이어를 통과 >> 출력 채널\n",
    "    final = self.conv_layer1(final)\n",
    "\n",
    "    # Tanh 활성화 함수 통과 >> 최종 이미지 반환\n",
    "    return self.activation(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 업샘플링 합성곱 블록 클래스를 정의함.\n",
    "class UpConvBlock(nn.Module):\n",
    "    # 모듈 초기화. ip_sz: 입력 채널, op_sz: 출력 채널, dropout: 드롭아웃 확률을 받음.\n",
    "    def __init__(self, ip_sz, op_sz, dropout=0.0):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "\n",
    "        # 블록을 구성할 레이어 리스트를 정의함.\n",
    "        self.layers = [\n",
    "            # 전치 합성곱(ConvTranspose2d)을 사용해 업샘플링함. 커널 4, 스트라이드 2, 패딩 1로 해상도를 2배로 높임.\n",
    "            nn.ConvTranspose2d(ip_sz, op_sz, 4, 2, 1),\n",
    "            # 배치 정규화 대신 인스턴스 정규화(InstanceNorm2d)를 적용함. (Pix2Pix GAN에서 흔히 사용됨)\n",
    "            nn.InstanceNorm2d(op_sz),\n",
    "            # ReLU 활성화 함수를 적용함.\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        # 드롭아웃 확률이 0.0보다 크면 드롭아웃 레이어를 추가함.\n",
    "        if dropout:\n",
    "            self.layers += [nn.Dropout(dropout)]\n",
    "\n",
    "    # 순전파 함수를 정의함. x: 이전 디코더 출력, enc_ip: 스킵 커넥션으로 받은 인코더 출력을 입력받음.\n",
    "    def forward(self, x, enc_ip):\n",
    "        # 정의된 레이어들을 nn.Sequential로 묶어 x를 통과시킴.\n",
    "        x = nn.Sequential(*(self.layers))(x)\n",
    "\n",
    "        # 업샘플링된 결과(x)와 해당 인코더 출력(enc_ip)을 채널 차원(1번)을 따라 결합(concatenate)함.\n",
    "        op = torch.cat((x, enc_ip), 1)\n",
    "\n",
    "        # 결합된 특징 맵을 반환함.\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 다운샘플링 합성곱 블록 클래스를 정의함.\n",
    "class DownConvBlock(nn.Module):\n",
    "    # 모듈 초기화. ip_sz: 입력 채널, op_sz: 출력 채널, norm: 정규화 사용 여부, dropout: 드롭아웃 확률을 받음.\n",
    "    def __init__(self, ip_sz, op_sz, norm=True, dropout=0.0):\n",
    "        super(DownConvBlock, self).__init__()\n",
    "\n",
    "        # 첫 번째 레이어: 4x4 합성곱을 정의함. stride=2, padding=1로 해상도를 절반으로 줄임.\n",
    "        self.layers = [nn.Conv2d(ip_sz, op_sz, 4, 2, 1)]\n",
    "\n",
    "        # 정규화(norm)가 True인 경우 인스턴스 정규화 레이어를 추가함.\n",
    "        if norm:\n",
    "            self.layers.append(nn.InstanceNorm2d(op_sz))\n",
    "\n",
    "        # Leaky ReLU 활성화 함수를 추가함.\n",
    "        self.layers += [nn.LeakyReLU(0.2)]\n",
    "\n",
    "        # 드롭아웃 확률이 0.0보다 큰 경우 드롭아웃 레이어를 추가함.\n",
    "        if dropout:\n",
    "            self.layers += [nn.Dropout(dropout)]\n",
    "\n",
    "    # 순전파 함수를 정의함.\n",
    "    def forward(self, x):\n",
    "        # 정의된 레이어들을 nn.Sequential로 묶어 x를 통과시킴.\n",
    "        op = nn.Sequential(*(self.layers))(x)\n",
    "\n",
    "        # 최종 특징 맵을 반환함.\n",
    "        return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pix2Pix 판별자 클래스를 정의함.\n",
    "class Pix2PixDiscriminator(nn.Module):\n",
    "    # 모델의 레이어들을 정의하여 초기화함. chnls_in: 입력 이미지 채널 수를 받음.\n",
    "    def __init__(self, chnls_in=3):\n",
    "        super(Pix2PixDiscriminator, self).__init__()\n",
    "\n",
    "        # 합성곱, 정규화, 활성화 함수로 구성된 판별 블록을 정의하는 헬퍼 함수임.\n",
    "        def disc_conv_block(chnls_in, chnls_op, norm=1):\n",
    "            # 4x4 합성곱, stride=2, padding=1로 해상도를 절반으로 줄임.\n",
    "            layers = [nn.Conv2d(chnls_in, chnls_op, 4, stride=2, padding=1)]\n",
    "\n",
    "            # 정규화(norm)가 True인 경우 인스턴스 정규화 레이어를 추가함.\n",
    "            if normalization: # 'normalization' 변수가 클래스 외부에서 정의되었다고 가정함.\n",
    "                layers.append(nn.InstanceNorm2d(chnls_op))\n",
    "\n",
    "            # Leaky ReLU 활성화 함수를 추가함.\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 첫 번째 레이어(lyr1): 입력 이미지(실제 + 생성)를 결합하므로 채널은 chnls_in * 2임.\n",
    "        # 정규화는 사용하지 않음(norm=0).\n",
    "        self.lyr1 = disc_conv_block(chnls_in * 2, 64, norm=0)\n",
    "        # 두 번째 레이어(lyr2): 64채널을 128채널로 변환함.\n",
    "        self.lyr2 = disc_conv_block(64, 128)\n",
    "        # 세 번째 레이어(lyr3): 128채널을 256채널로 변환함.\n",
    "        self.lyr3 = disc_conv_block(128, 256)\n",
    "        # 네 번째 레이어(lyr4): 256채널을 512채널로 변환함.\n",
    "        self.lyr4 = disc_conv_block(256, 512)\n",
    "\n",
    "    # 데이터의 순전파 경로를 정의함.\n",
    "    def forward(self, real_image, translated_image):\n",
    "        # 실제 이미지와 생성된 이미지를 채널 차원(1번)을 따라 결합하여 입력(ip)을 만듦.\n",
    "        # Pix2Pix 조건부 GAN\n",
    "        ip = torch.cat((real_image, translated_image), 1)\n",
    "\n",
    "        # 합성곱 블록들을 순서대로 통과시킴.\n",
    "        # 해상도는 점진적으로 줄어들고, 채널 증가\n",
    "        op = self.lyr1(ip)\n",
    "        op = self.lyr2(op)\n",
    "        op = self.lyr3(op)\n",
    "        op = self.lyr4(op)\n",
    "\n",
    "        # 최종 합성곱 레이어 전 패딩을 적용함.\n",
    "        op = nn.ZeroPad2d((1, 0, 1, 0))(op)\n",
    "        # 최종 512채널을 1채널 출력으로 변환하는 합성곱 레이어를 통과시킴.\n",
    "        op = nn.Conv2d(512, 1, 4, padding=1)(op)\n",
    "\n",
    "        # 최종 패치별 진위 여부 예측 맵을 반환함. (Sigmoid는 외부에서 적용될 수 있음)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pix2pix 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                          # 파이토치 기본 모듈을 불러옴\n",
    "import torch.nn as nn                 # 신경망 레이어를 제공하는 nn 모듈을 불러옴\n",
    "import torch.nn.functional as F       # 보조 함수들(ReLU, interpolate 등)을 제공하는 F 모듈을 불러옴\n",
    "from torch.utils.data import DataLoader, Subset  # 미니배치 생성을 위한 DataLoader와 Subset을 불러옴\n",
    "\n",
    "import torchvision                    # 토치비전(이미지용 데이터셋/모듈)을 불러옴\n",
    "import torchvision.transforms as T    # 이미지 변환을 위한 transforms 모듈을 불러옴\n",
    "\n",
    "import matplotlib.pyplot as plt       # 시각화를 위한 matplotlib.pyplot을 불러옴\n",
    "import numpy as np                   # 텐서를 넘파이로 바꿔서 그림에 쓰기 위해 numpy를 불러옴\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU가 있으면 cuda, 없으면 cpu를 선택함\n",
    "print(\"사용 중인 device:\", device)                                     # 현재 선택된 device를 출력함"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOufR0U1qbPBWkru4Lf1VN+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
