{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°•ì˜_6ê¸°_AIì‘ìš©_7ì°¨ì‹œ_01_dcgan.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fdEBqj-6h17G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# íŒë³„ê¸° í•™ìŠµ\\ndef train_discriminator(real_images, generator, discriminator, optimizer_d):\\n    # ì§„ì§œ ì´ë¯¸ì§€ íŒë³„\\n    real_output = discriminator(real_images)\\n    real_loss = F.binary_cross_entropy(real_output, torch.ones_like(real_output))\\n\\n    # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± ë° íŒë³„\\n    z = torch.randn(batch_size, latent_dim)\\n    fake_images = generator(z)\\n    fake_output = discriminator(fake_images.detach())\\n    fake_loss = F.binary_cross_entropy(fake_output, torch.zeros_like(fake_output))\\n\\n    # ì „ì²´ ì†ì‹¤\\n    d_loss = real_loss + fake_loss\\n\\n    optimizer_d.zero_grad()\\n    d_loss.backward()\\n    optimizer_d.step()\\n\\n# ìƒì„±ê¸° í•™ìŠµ\\ndef train_generator(generator, discriminator, optimizer_g):\\n    z = torch.randn(batch_size, latent_dim)\\n    fake_images = generator(z)\\n    output = discriminator(fake_images)\\n\\n    # ìƒì„±ê¸°ëŠ” íŒë³„ê¸°ë¥¼ ì†ì´ë ¤ê³  í•¨\\n    g_loss = F.binary_cross_entropy(output, torch.ones_like(output))\\n\\n    optimizer_g.zero_grad()\\n    g_loss.backward()\\n    optimizer_g.step()\\n```\\n\\n---\\n## ğŸ“„ 6í˜ì´ì§€: DCGAN ì†Œê°œ\\n### ğŸ—ï¸ DCGAN(Deep Convolutional GAN)\\nì´ì œ GANì˜ ë°œì „ëœ í˜•íƒœì¸ **DCGAN**ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤!\\nDCGANì€ ê¸°ë³¸ GANì— **CNN(Convolutional Neural Network)** êµ¬ì¡°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.\\n#### ì™œ DCGANì´ í•„ìš”í–ˆì„ê¹Œ?\\nê¸°ë³¸ GANì˜ ë¬¸ì œì :\\n- í•™ìŠµì´ ë¶ˆì•ˆì •\\n- ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì´ ì–´ë ¤ì›€\\n- ëª¨ë“œ ë¶•ê´´(mode collapse) í˜„ìƒ ë°œìƒ\\nDCGANì˜ í•´ê²°ì±…:\\n- **í•©ì„±ê³± ì¸µ** ì‚¬ìš©ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ê³µê°„ì  íŠ¹ì§• í•™ìŠµ\\n- **ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)** ë¡œ í•™ìŠµ ì•ˆì •í™”\\n- ì²´ê³„ì ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì§€ì¹¨ ì œê³µ\\n\\n---\\n## ğŸ“„ 7í˜ì´ì§€: DCGAN ìƒì„±ê¸° êµ¬ì¡°\\n### ğŸ¨ DCGAN ìƒì„±ê¸°ì˜ ìƒì„¸ êµ¬ì¡°\\nìƒì„±ê¸°ëŠ” ì‘ì€ ë…¸ì´ì¦ˆ ë²¡í„°ì—ì„œ ì‹œì‘í•´ ì ì§„ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ \"í‚¤ì›Œë‚˜ê°€ëŠ”\" êµ¬ì¡°ì…ë‹ˆë‹¤.\\n\\n#### ë‹¨ê³„ë³„ ê³¼ì •:\\n\\n1. **ì…ë ¥ ë‹¨ê³„**\\n```\\n   64ì°¨ì› ë…¸ì´ì¦ˆ â†’ ì„ í˜• ë³€í™˜ â†’ 16Ã—16Ã—128 íŠ¹ì§• ë§µ\\n```\\n   - ë¹„ìœ : ì‘ì€ ì”¨ì•—(64ì°¨ì›)ì„ ì‹¬ì–´ì„œ ì²« ìƒˆì‹¹(16Ã—16Ã—128) ë§Œë“¤ê¸°\\n\\n2. **ì—…ìƒ˜í”Œë§ 1ë‹¨ê³„**\\n```\\n   16Ã—16Ã—128 â†’ 32Ã—32Ã—128\\n```\\n   - ì „ì¹˜ í•©ì„±ê³±(Transposed Convolution) ì‚¬ìš©\\n   - í¬ê¸°ë¥¼ 2ë°°ë¡œ í™•ëŒ€\\n   - 3Ã—3 ì»¤ë„ë¡œ ì„¸ë°€í•œ íŠ¹ì§• ì¶”ê°€\\n\\n3. **ì—…ìƒ˜í”Œë§ 2ë‹¨ê³„**\\n```\\n   32Ã—32Ã—128 â†’ 64Ã—64Ã—128\\n```\\n   - ë‹¤ì‹œ 2ë°° í™•ëŒ€\\n   - ë” ì„¸ë°€í•œ ë””í…Œì¼ ì¶”ê°€\\n\\n4. **ìµœì¢… ì¶œë ¥**\\n```\\n   64Ã—64Ã—128 â†’ 64Ã—64Ã—3 (RGB)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAN ì½”ë“œ\n",
    "   # ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì£¼ì„ì²˜ë¦¬  \n",
    "'''\n",
    "# íŒë³„ê¸° í•™ìŠµ\n",
    "def train_discriminator(real_images, generator, discriminator, optimizer_d):\n",
    "    # ì§„ì§œ ì´ë¯¸ì§€ íŒë³„\n",
    "    real_output = discriminator(real_images)\n",
    "    real_loss = F.binary_cross_entropy(real_output, torch.ones_like(real_output))\n",
    "   \n",
    "    # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± ë° íŒë³„\n",
    "    z = torch.randn(batch_size, latent_dim)\n",
    "    fake_images = generator(z)\n",
    "    fake_output = discriminator(fake_images.detach())\n",
    "    fake_loss = F.binary_cross_entropy(fake_output, torch.zeros_like(fake_output))\n",
    "   \n",
    "    # ì „ì²´ ì†ì‹¤\n",
    "    d_loss = real_loss + fake_loss\n",
    "   \n",
    "    optimizer_d.zero_grad()\n",
    "    d_loss.backward()\n",
    "    optimizer_d.step()\n",
    "   \n",
    "# ìƒì„±ê¸° í•™ìŠµ\n",
    "def train_generator(generator, discriminator, optimizer_g):\n",
    "    z = torch.randn(batch_size, latent_dim)\n",
    "    fake_images = generator(z)\n",
    "    output = discriminator(fake_images)\n",
    "   \n",
    "    # ìƒì„±ê¸°ëŠ” íŒë³„ê¸°ë¥¼ ì†ì´ë ¤ê³  í•¨\n",
    "    g_loss = F.binary_cross_entropy(output, torch.ones_like(output))\n",
    "   \n",
    "    optimizer_g.zero_grad()\n",
    "    g_loss.backward()\n",
    "    optimizer_g.step()\n",
    "```\n",
    "\n",
    "---\n",
    "## ğŸ“„ 6í˜ì´ì§€: DCGAN ì†Œê°œ\n",
    "### ğŸ—ï¸ DCGAN(Deep Convolutional GAN)\n",
    "ì´ì œ GANì˜ ë°œì „ëœ í˜•íƒœì¸ **DCGAN**ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤!\n",
    "DCGANì€ ê¸°ë³¸ GANì— **CNN(Convolutional Neural Network)** êµ¬ì¡°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "#### ì™œ DCGANì´ í•„ìš”í–ˆì„ê¹Œ?\n",
    "ê¸°ë³¸ GANì˜ ë¬¸ì œì :\n",
    "- í•™ìŠµì´ ë¶ˆì•ˆì •\n",
    "- ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì´ ì–´ë ¤ì›€\n",
    "- ëª¨ë“œ ë¶•ê´´(mode collapse) í˜„ìƒ ë°œìƒ\n",
    "DCGANì˜ í•´ê²°ì±…:\n",
    "- **í•©ì„±ê³± ì¸µ** ì‚¬ìš©ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ê³µê°„ì  íŠ¹ì§• í•™ìŠµ\n",
    "- **ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)** ë¡œ í•™ìŠµ ì•ˆì •í™”\n",
    "- ì²´ê³„ì ì¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì§€ì¹¨ ì œê³µ\n",
    "\n",
    "---\n",
    "## ğŸ“„ 7í˜ì´ì§€: DCGAN ìƒì„±ê¸° êµ¬ì¡°\n",
    "### ğŸ¨ DCGAN ìƒì„±ê¸°ì˜ ìƒì„¸ êµ¬ì¡°\n",
    "ìƒì„±ê¸°ëŠ” ì‘ì€ ë…¸ì´ì¦ˆ ë²¡í„°ì—ì„œ ì‹œì‘í•´ ì ì§„ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ \"í‚¤ì›Œë‚˜ê°€ëŠ”\" êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ë‹¨ê³„ë³„ ê³¼ì •:\n",
    "\n",
    "1. **ì…ë ¥ ë‹¨ê³„**\n",
    "```\n",
    "   64ì°¨ì› ë…¸ì´ì¦ˆ â†’ ì„ í˜• ë³€í™˜ â†’ 16Ã—16Ã—128 íŠ¹ì§• ë§µ\n",
    "```\n",
    "   - ë¹„ìœ : ì‘ì€ ì”¨ì•—(64ì°¨ì›)ì„ ì‹¬ì–´ì„œ ì²« ìƒˆì‹¹(16Ã—16Ã—128) ë§Œë“¤ê¸°\n",
    "\n",
    "2. **ì—…ìƒ˜í”Œë§ 1ë‹¨ê³„**\n",
    "```\n",
    "   16Ã—16Ã—128 â†’ 32Ã—32Ã—128\n",
    "```\n",
    "   - ì „ì¹˜ í•©ì„±ê³±(Transposed Convolution) ì‚¬ìš©\n",
    "   - í¬ê¸°ë¥¼ 2ë°°ë¡œ í™•ëŒ€\n",
    "   - 3Ã—3 ì»¤ë„ë¡œ ì„¸ë°€í•œ íŠ¹ì§• ì¶”ê°€\n",
    "\n",
    "3. **ì—…ìƒ˜í”Œë§ 2ë‹¨ê³„**\n",
    "```\n",
    "   32Ã—32Ã—128 â†’ 64Ã—64Ã—128\n",
    "```\n",
    "   - ë‹¤ì‹œ 2ë°° í™•ëŒ€\n",
    "   - ë” ì„¸ë°€í•œ ë””í…Œì¼ ì¶”ê°€\n",
    "\n",
    "4. **ìµœì¢… ì¶œë ¥**\n",
    "```\n",
    "   64Ã—64Ã—128 â†’ 64Ã—64Ã—3 (RGB)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Discriminator(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n\\n        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1)\\n\\n        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\\n        self.bn2 = nn.BatchNorm2d(128)\\n\\n        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\\n        self.bn3 = nn.BatchNorm2d(256)\\n\\n        self.conv4 = nn.Conv2d(256, 512, 3, stride=2, padding=1)\\n        self.bn4 = nn.BatchNorm2d(512)\\n\\n        self.fc = nn.Linear(512*4*4, 1)\\n\\n    def forward(self, x):\\n        x = F.leaky_relu(self.conv1(x), 0.2)\\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\\n        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)\\n\\n        x = x.view(x.size(0), -1)  # flatten\\n        x = torch.sigmoid(self.fc(x))\\n\\n        return x\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.fc = nn.Linear(512*4*4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        \n",
    "        return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eps=1\n",
    "bsize=32\n",
    "lrate=0.001\n",
    "\n",
    "# ì ì¬ ê³µê°„(latent space)ì˜ ì°¨ì›(dimension)ì„ 64ë¡œ ì„¤ì •í•¨. (ìƒì„± ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°)\n",
    "lat_dimension=64\n",
    "image_sz=64\n",
    "chnls=1\n",
    "# í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ë¡œê·¸ë¡œ ì¶œë ¥í•  ê°„ê²©(ë¯¸ë‹ˆ ë°°ì¹˜ ìˆ˜)ì„ 200ìœ¼ë¡œ ì„¤ì •í•¨.\n",
    "logging_intv=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN ìƒì„±ì(Generator) í´ë˜ìŠ¤ ì •ì˜\n",
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        # ì„ í˜• ë ˆì´ì–´ì˜ ì¶œë ¥ í•´ìƒë„ë¥¼ ê³„ì‚°(ì˜ˆ: 64*64 image 1/4 í¬ê¸° >> 16)\n",
    "        self.inp_sz = image_sz // 4\n",
    "        # ì²« ë²ˆì§¸ ë ˆì´ì–´: ì ì¬ê³µê°„(lat_dimension)ì„ (128*inp_sz) í¬ê¸° ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´ ì •ì˜\n",
    "        self.lin = nn.Linear(lat_dimension, 128*self.inp_sz*self.inp_sz)\n",
    "        # ì„ í˜• ë ˆì´ì–´ ì¶œë ¥ >> ë°°ì¹˜ì •ê·œí™”\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        # ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ 2ë°°ë¡œ ì—…ìƒ˜í”Œë§\n",
    "        self.up1 = nn.Upsample(scale_factor=2)\n",
    "        # ì±„ë„ 128 ê°œ ìœ ì§€í•˜ëŠ” 3*3 ì»¤ë„ ì´ìš©, í•©ì„±ê³± ë ˆì´ì–´ ì •ì˜\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        # ë°°ì¹˜ì •ê·œí™” ë ˆì´ì–´ ì •ì˜ (momentum=0.8 ì‚¬ìš©)\n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        # Leaky Relu í™œì„±í™” í•¨ìˆ˜ ì •ì˜ (ìŒìˆ˜ ê¸°ìš¸ê¸° 0.2 ì‚¬ìš©)\n",
    "        self.rl1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        # ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ 2ë°°ë¡œ ì—…ìƒ˜í”Œë§\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        # ì±„ë„ì„ 128 >> 64ê°œë¡œ ì¤„ì´ëŠ” 3*3 í•©ì„±ê³± ë ˆì´ì–´ ì •ì˜\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        # ë°°ì¹˜ì •ê·œí™” ë ˆì´ì–´ ì •ì˜ (momentum=0.8 ì‚¬ìš©)\n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        # Leaky Relu í™œì„±í™” í•¨ìˆ˜ ì •ì˜ (ìŒìˆ˜ ê¸°ìš¸ê¸° 0.2 ì‚¬ìš©)\n",
    "        self.rl2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        # ìµœì¢… ì±„ë„ ìˆ˜ë¥¼ chnls(1ê°œ)ë¡œ ë§Œë“œëŠ” 3*3 í•©ì„±ê³± ë ˆì´ì–´ ì •ì˜\n",
    "        self.cn3 = nn.Conv2d(64, chnls, 3, stride=1, padding=1)\n",
    "        # ìµœì¢… ì¶œë ¥ ì´ë¯¸ì§€ í”½ì…€ê°’ì„ [-1,1] ë²”ìœ„ë¡œ ì œí•œ : Tahn í™œì„±í™” í•¨ìˆ˜\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ì„ í˜• ë ˆì´ì–´ í†µê³¼\n",
    "        x = self.lin(x)\n",
    "        # í…ì„œë¥¼ (ë°°ì¹˜ í¬ê¸°, ì±„ë„, ë†’ì´, ë„ˆë¹„) 4ì°¨ì› í˜•íƒœë¡œ ì¬êµ¬ì„±\n",
    "        x = x.view(x.shape[0], 128, self.inp_sz, self.inp_sz)\n",
    "        # ë°°ì¹˜ ì •ê·œí™” 1ì„ í†µí™”\n",
    "        x = self.bn1(x)\n",
    "        # ì—…ìƒ˜í”Œë§ 1 í†µê³¼ >> í•´ìƒë„ 2ë°°\n",
    "        x = self.up1(x)\n",
    "        # í•©ì„±ê³± 1 í†µê³¼\n",
    "        x = self.cn1(x)\n",
    "        # ë°°ì¹˜ ì •ê·œí™” 2ì„ í†µê³¼\n",
    "        x = self.bn2(x)\n",
    "        # Leaky Relu í†µê³¼\n",
    "        x = self.rl1(x)\n",
    "        # ì—…ìƒ˜í”Œë§ 2 >> í•´ìƒë„ 2ë°°\n",
    "        x = self.up2(x)\n",
    "        # í•©ì„±ê³± 2 í†µê³¼\n",
    "        x = self.cn2(x)\n",
    "        # ë°°ì¹˜ ì •ê·œí™” 3ì„ í†µê³¼\n",
    "        x = self.bn3(x)\n",
    "        # Leaky Relu í†µê³¼\n",
    "        x = self.rl2(x)\n",
    "        # ìµœì¢… í•©ì„±ê³± ë ˆì´ì–´ 3 í†µê³¼\n",
    "        x = self.cn3(x)\n",
    "        # Tanh í™œì„±í™” í•¨ìˆ˜ í†µê³¼ >> ìµœì¢… ì¶œë ¥(out)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN íŒë³„ì í´ë˜ìŠ¤ ì •ì˜\n",
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "        # í•©ì„±ê³±, leaky relu, dropout >> í•˜ë‚˜ì˜ íŒë³„ëª¨ë“ˆ ì •ì˜í•˜ëŠ” í—¬í¼í•¨ìˆ˜\n",
    "        def disc_module(ip_chnls, op_chnls, bnorm=True):\n",
    "            # downsampling : stride = 2\n",
    "            mod = [nn.Conv2d(ip_chnls, op_chnls, 3, 2, 1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout2d(0.3)]\n",
    "            # ë°°ì¹˜ ì •ê·œí™”(bnorm)ê°€ ìš”ì²­ëœ ê²½ìš° ëª¨ë“ˆì— ì¶”ê°€\n",
    "            if bnorm:\n",
    "                mod += [nn.BatchNorm2d(op_chnls)]\n",
    "            return mod\n",
    "\n",
    "        # íŒë³„ëª¨ë“ˆì„ ì—°ê²°í•˜ì—¬ íŒë³„ì ëª¨ë¸ì˜ íŠ¹ì§• ì¶”ì¶œë¶€(disc_model) êµ¬ì„±\n",
    "        self.disc_model = nn.Sequential(\n",
    "            # ì²« ë²ˆì§¸ ëª¨ë“ˆ : ì…ë ¥ì±„ë„(chnls)ì„ 16ê°œë¡œ ë§Œë“¦, ë°°ì¹˜ì •ê·œí™” ì‚¬ìš©X\n",
    "            *disc_module(chnls, 16, bnorm=False),\n",
    "            *disc_module(16, 32),\n",
    "            *disc_module(32, 64),\n",
    "            *disc_module(64, 128)\n",
    "        )\n",
    "        # 4ë²ˆì˜ ë‹¤ìš´ìƒ˜í”Œë§ í›„ ìµœì¢… í•´ìƒë„ ê³„ì‚°\n",
    "        ds_size = image_sz // 2 ** 4\n",
    "\n",
    "        # íŠ¹ì§•ë§µì„ ë‹¨ì¼ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìµœì¢…ë ˆì´ì–´ ì •ì˜\n",
    "        self.adverse_lyr = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size * ds_size, 1),\n",
    "            # ì…ë ¥ê°’ 128 * ds_size * ds_size\n",
    "            # >> featuremapì„ í•˜ë‚˜ì˜ ë²¡í„°ê°’ìœ¼ë¡œ ì¶œë ¥ (í‰íƒ„í™”)\n",
    "            nn.Sigmoid() # ì¶œë ¥ (0 : ê°€ì§œ, 1 : ì§„ì§œ)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        # b, c, h, w -> b, c*h*w\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.adverse_lyr(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = GANGenerator()\n",
    "disc = GANDiscriminator()\n",
    "\n",
    "# ì†ì‹¤í•¨ìˆ˜(BCELoss) ì´ì§„ë¶„ë¥˜\n",
    "adv_loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "dloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((image_sz, image_sz)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=bsize,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ìµœì í™” í•¨ìˆ˜ê°€ ë³„ê°œë¡œ ë“¤ì–´ê°€ê¸° ë•Œë¬¸\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lrate)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "os.makedirs('./img_mnist', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1], Batch [0/1875], Generator Loss: 0.7737, Discriminator Loss: 0.5645\n",
      "Epoch [0/1], Batch [200/1875], Generator Loss: 1.0721, Discriminator Loss: 0.7863\n",
      "Epoch [0/1], Batch [400/1875], Generator Loss: 1.8120, Discriminator Loss: 0.4144\n",
      "Epoch [0/1], Batch [600/1875], Generator Loss: 1.0625, Discriminator Loss: 0.6979\n",
      "Epoch [0/1], Batch [800/1875], Generator Loss: 0.9163, Discriminator Loss: 0.3892\n",
      "Epoch [0/1], Batch [1000/1875], Generator Loss: 1.0458, Discriminator Loss: 0.4490\n",
      "Epoch [0/1], Batch [1200/1875], Generator Loss: 0.9052, Discriminator Loss: 0.6015\n",
      "Epoch [0/1], Batch [1400/1875], Generator Loss: 1.9773, Discriminator Loss: 0.2389\n",
      "Epoch [0/1], Batch [1600/1875], Generator Loss: 2.9264, Discriminator Loss: 0.2236\n",
      "Epoch [0/1], Batch [1800/1875], Generator Loss: 2.4123, Discriminator Loss: 0.3125\n"
     ]
    }
   ],
   "source": [
    "for ep in range(num_eps):\n",
    "    # ë°ì´í„° ë¡œë”ë¥¼ ëŒë©´ì„œ ë¯¸ë‹ˆë°°ì¹˜(ì´ë¯¸ì§€O <> ë¼ë²¨X) ì²˜ë¦¬\n",
    "    for idx, (images, _) in enumerate(dloader):\n",
    "        # ì§„ì§œ <> ê°€ì§œ ì‚¬ì´ì— fill_() ì¸ìˆ˜ ì°¨ì´\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë‹µ ë ˆì´ë¸”(1, 0) í…ì„œ ìƒì„±(ë³€í™”ë„ ì¶”ì  ë¹„í™œì„±í™”)\n",
    "        # good_img = Variable(torch.FloatTensor(image.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        good_img = torch.ones(images.size(0), 1)\n",
    "\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë‹µ ë ˆì´ë¸”(1, 0) í…ì„œ ìƒì„±(ë³€í™”ë„ ì¶”ì  ë¹„í™œì„±í™”)\n",
    "        # bad_img = Variable(torch.FloatTensor(image.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "        bad_img = torch.zeros(images.size(0), 1)\n",
    "\n",
    "        # ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ pytorch float tensor íƒ€ì…ì˜ Variableë¡œ ë³€í™˜\n",
    "        # actual_img = Varialbe(images.type(torch.FloatTensor))\n",
    "        actual_img = images.to(dtype=torch.float32)\n",
    "\n",
    "        # ìƒì„±ì(Generator) í›ˆë ¨ ë‹¨ê³„\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # ì •ê·œë¶„í¬ì—ì„œ random noise vector ìƒì„± : lat_dimention í¬ê¸°\n",
    "        # noise = Variable(torch.FloatTensor(np.random.normal(0,1,(images.shape[0], lat_dimention))))\n",
    "        noise = torch.randn(images.size(0), lat_dimension)\n",
    "\n",
    "        # ìƒì„±ì ëª¨ë¸ì— ë…¸ì´ì¦ˆ(z) ë„£ì–´ì„œ ê°€ì§œ ì´ë¯¸ì§€ (gen_images) ìƒì„±\n",
    "        gen_images = gen(noise)\n",
    "        # ìƒì„±ì ì†ì‹¤ê³„ì‚° : ìƒì„±ì ì´ë¯¸ì§€ë¥¼ ì§„ì§œ (good_img = 1)ë¼ê³  ì†ì¼ ìˆ˜ ìˆëŠ”ì§€ í‰ê°€\n",
    "        gen_loss = adv_loss_func(disc(gen_images), good_img)\n",
    "        # ì—­ì „íŒŒ\n",
    "        gen_loss.backward()\n",
    "        # ìƒì„±ì íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "        opt_gen.step()\n",
    "\n",
    "        # íŒë³„ì í›ˆë ¨\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        actual_image_loss = adv_loss_func(disc(actual_img), good_img)\n",
    "        fake_image_loss = adv_loss_func(disc(gen_images.detach()), bad_img)\n",
    "\n",
    "        disc_loss = (actual_image_loss + fake_image_loss) / 2\n",
    "\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # í˜„ì¬ê¹Œì§€ ì™„ë£Œëœ ë°°ì¹˜ì˜ ì´ ê°œìˆ˜ ê³„ì‚°\n",
    "        batches_completed = ep * len(dloader) + idx\n",
    "\n",
    "        # ë¡œê¹… ê°„ê²©(logging_intv)ë§ˆë‹¤ í˜„ì¬ì†ì‹¤ ì¶œë ¥í•˜ê³  ì´ë¯¸ì§€ ì €ì¥\n",
    "        if batches_completed % logging_intv == 0:\n",
    "            print(f\"Epoch [{ep}/{num_eps}], Batch [{idx}/{len(dloader)}], Generator Loss: {gen_loss.item():.4f}, Discriminator Loss: {disc_loss.item():.4f}\")\n",
    "            save_image(gen_images.data[:25], f'img_mnist/{batches_completed}.png', nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m image_dir = \u001b[33m'\u001b[39m\u001b[33mimg_mnist\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ë§Œì•½ Windows í™˜ê²½ì´ë¼ë©´: image_dir = 'C:/Users/username/Desktop/images_mnist' ë“±ìœ¼ë¡œ ë³€ê²½ í•„ìš”\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ natsortë¡œ ìì—° ì •ë ¬ (ì˜ˆ: image1, image2, image10 ìˆœì„œë¡œ ì •ë ¬)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# sorted_files = natsort.natsorted(os.listdir(image_dir))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mfile_list\u001b[49m.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 2. ì •ë ¬ëœ íŒŒì¼ëª…ì— ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\u001b[39;00m\n\u001b[32m     13\u001b[39m image_list = [os.path.join(image_dir, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sorted_files]\n",
      "\u001b[31mNameError\u001b[39m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import natsort # ìì—° ì •ë ¬ ëª¨ë“ˆ\n",
    "\n",
    "# --- ê²½ë¡œ ì„¤ì • (ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ì¡°ì • í•„ìš”) ---\n",
    "image_dir = 'img_mnist'\n",
    "# ë§Œì•½ Windows í™˜ê²½ì´ë¼ë©´: image_dir = 'C:/Users/username/Desktop/images_mnist' ë“±ìœ¼ë¡œ ë³€ê²½ í•„ìš”\n",
    "\n",
    "# 1. ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ natsortë¡œ ìì—° ì •ë ¬ (ì˜ˆ: image1, image2, image10 ìˆœì„œë¡œ ì •ë ¬)\n",
    "# sorted_files = natsort.natsorted(os.listdir(image_dir))\n",
    "file_list.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "# 2. ì •ë ¬ëœ íŒŒì¼ëª…ì— ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "image_list = [os.path.join(image_dir, x) for x in sorted_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loaded_images = []\n",
    "\n",
    "for path in image_list:\n",
    "   img = cv2.imread(path)\n",
    "\n",
    "   if img is None:\n",
    "      print(f\"ê²½ë¡œì— ì˜¤ë¥˜ê°€ ìˆì–´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}\")\n",
    "      continue\n",
    "      # ì´ë¯¸ì§€ ë¡œë“œí•˜ì§€ ëª»í–ˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "   img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "   loaded_images.append(img_rgb)\n",
    "\n",
    "\n",
    "for i in range(len(loaded_images)):\n",
    "    plt.figure()\n",
    "\n",
    "    plt.imshow(loaded_images[i])\n",
    "    plt.title(f'Displayed Image {image_list[i].split('/')}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNu7n43vc3OuqV98WsJDrLx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
