{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47739d78",
   "metadata": {},
   "source": [
    "강의_6기_AI응용_6차시_01_GramMatrix와 Loss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec31884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch의 핵심 라이브러리를 불러옴.\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79f18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram Matrix 계산하는 파이토치 모듈 정의\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b, c, h, w = input.size()\n",
    "        features = input.view(b, c, h * w)\n",
    "\n",
    "        # 배치 행렬곱(bmm) -> gram matrix 계산\n",
    "        # features: (b, c, h*w)\n",
    "        # features.transpose(1,2): (b, h*w, c)\n",
    "        # 출력 : (b, c, c) \n",
    "        G = torch.bmm(features, features.transpose(1,2))\n",
    "\n",
    "        # G 행렬을 h*w로 나누어 정규화\n",
    "        G.div_(h * w)\n",
    "\n",
    "        return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af7b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gram matrix에 대해 MSE(평균제곱오차) 손실 계산하는 모듈\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        # GramMatrix 모듈 통과 > gram matrix 생성\n",
    "        # target은 이미지의 gram matrix\n",
    "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb4efd",
   "metadata": {},
   "source": [
    "[VGG 구조 패턴]\n",
    "\n",
    "- Block 1: 3→64→64 (얕은 특징: 선, 모서리)\n",
    "- Block 2: 64→128→128 (중간 특징: 질감)\n",
    "- Block 3: 128→256→256→256 (깊은 특징: 패턴)\n",
    "- Block 4: 256→512→512→512 (더 복잡한 특징)\n",
    "- Block 5: 512→512→512→512 (추상적 특징)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b629c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, pool='max'):\n",
    "        super(VGG, self).__init__()\n",
    "        #vgg modules\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        if pool == 'max': # 특징 최대값 추출(뚜렷한 특징)\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pool == 'avg': # 특징을 평균 추출(부드러운 특징)\n",
    "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x, out_keys):\n",
    "        out = {}\n",
    "        out['r11'] = F.relu(self.conv1_1(x))\n",
    "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
    "        out['p1'] = self.pool1(out['r12'])\n",
    "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
    "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
    "        out['p2'] = self.pool2(out['r22'])\n",
    "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
    "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
    "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
    "        out['r34'] = F.relu(self.conv3_4(out['r33']))\n",
    "        out['p3'] = self.pool3(out['r34'])\n",
    "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
    "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
    "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
    "        out['r44'] = F.relu(self.conv4_4(out['r43']))\n",
    "        out['p4'] = self.pool4(out['r44'])\n",
    "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
    "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
    "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
    "        out['r54'] = F.relu(self.conv5_4(out['r53']))\n",
    "        out['p5'] = self.pool5(out['r54'])\n",
    "        return [out[key] for key in out_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7535320d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# GPU (CUDA) 사용이 가능하다면, 모든 손실 함수 모듈을 GPU 메모리로 이동시킴.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# loss_fns 리스트의 요소들을 새로운 모듈 인스턴스로 만들고 .cuda()를 적용\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# 리스트 복사를 방지하고 정확하게 GPU로 이동하기 위해 수정\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# for _ in style_layers : 개수만큼 인스턴스화\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     loss_fns = [GramMSELoss().to(\u001b[43mdevice\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m style_layers] + \\\n\u001b[32m     67\u001b[39m                [nn.MSELoss().to(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m content_layers]\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     69\u001b[39m     loss_fns = [GramMSELoss().to(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m style_layers] + \\\n\u001b[32m     70\u001b[39m                [nn.MSELoss().to(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m content_layers]\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "vgg = VGG()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 로드할 이미지 파일 이름들을 정의함. ('vangogh_starry_night.jpg', 'Tuebingen_Neckarfront.jpg')\n",
    "img1 = \"vangogh_starry_night.jpg\"\n",
    "img2 = \"Tuebingen_Neckarfront.jpg\"\n",
    "\n",
    "# 이미지 디렉토리와 파일 이름을 결합하여 PIL Image 객체 리스트로 로드함.\n",
    "img1 = Image.open(img1)\n",
    "img2 = Image.open(img2)\n",
    "imgs = []\n",
    "imgs.append(img1)\n",
    "imgs.append(img2)\n",
    "\n",
    "img_size = 512\n",
    "\n",
    "prep = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(), # c h w [0-1]\n",
    "    transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), # rgb -> bgr\n",
    "    transforms.Normalize(\n",
    "        mean=[0.40760392, 0.45795686, 0.48501961],\n",
    "        std=[1,1,1]\n",
    "        ),\n",
    "    transforms.Lambda(lambda x: x.mul_(255)), # 스케일\n",
    "])\n",
    "\n",
    "# pil 객체에 사전 정의된 전처리 함수 적용\n",
    "img_torch = [prep(img) for img in imgs]\n",
    "\n",
    "# variable 없어도 되는 것.\n",
    "if torch.cuda.is_available():\n",
    "    # 각 텐서에 배치 차원(unsqueeze(0))을 추가하고 GPU로 이동시킨 후, Variable로 감싸서 저장함.\n",
    "    # imgs_torch = [Variable(img.unsqueeze(0).cuda()) for img in img_torch]\n",
    "    imgs_torch = [img.unsqueeze(0).cuda() for img in img_torch]\n",
    "else:\n",
    "    # 각 텐서에 배치 차원만 추가하고 Variable로 감싸서 저장함.\n",
    "    # imgs_torch = [Variable(img.unsqueeze(0)) for img in img_torch]\n",
    "    imgs_torch = [img.unsqueeze(0) for img in img_torch]\n",
    "\n",
    "style_img, content_img = imgs_torch\n",
    "# opt_img = Variable(content_img.data.clone(), requires_grad=True)\n",
    "opt_img = content_img.data.clone().detach().requires_grad_(True)\n",
    "# 신경망 스타일 전이에서 CNN 가중치 학습X.\n",
    "# opt_img의 픽셀값만 학습하며 업데이트\n",
    "\n",
    "# 스타일 손실 계산할 VGG 레이어 이름정의\n",
    "# VGG 내부 특정 합성곱 레이어\n",
    "style_layers = ['r11','r21','r31','r41', 'r51']\n",
    "\n",
    "# 콘텐츠 손실 계산할 VGG 레이어 이름정의\n",
    "# 일반적으로 중간정도 레이어 중 하나 사용\n",
    "content_layers = ['r42']\n",
    "\n",
    "loss_layers = style_layers + content_layers\n",
    "\n",
    "# 각 스타일에 대해 GramMSELoss 모듈을 사용하고, \n",
    "# 콘텐츠에 대해 MSELoss 모듈을 사용하도록 리스트를 정의함.\n",
    "loss_fns = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
    "\n",
    "# GPU (CUDA) 사용이 가능하다면, 모든 손실 함수 모듈을 GPU 메모리로 이동시킴.\n",
    "if torch.cuda.is_available():\n",
    "    # loss_fns 리스트의 요소들을 새로운 모듈 인스턴스로 만들고 .cuda()를 적용\n",
    "    # 리스트 복사를 방지하고 정확하게 GPU로 이동하기 위해 수정\n",
    "    # for _ in style_layers : 개수만큼 인스턴스화\n",
    "    loss_fns = [GramMSELoss().to(device) for _ in style_layers] + \\\n",
    "               [nn.MSELoss().to(device) for _ in content_layers]\n",
    "else:\n",
    "    loss_fns = [GramMSELoss().to(device) for _ in style_layers] + \\\n",
    "               [nn.MSELoss().to(device) for _ in content_layers]\n",
    "\n",
    "# 스타일 손실에 적용할 가중치(알파)\n",
    "# 깊은 레이어(복잡한 패턴을 추출하는 레이어)일수록 낮은 가중치를 주는 경향\n",
    "# 왜냐하면, 가중치가 감소되니까.\n",
    "style_weights = [1e3/n**2 for n in [64, 128, 256, 512, 512]]\n",
    "\n",
    "# 콘텐츠 손실에 적용할 가중치(베타)\n",
    "content_weights = [1e0]\n",
    "content_weights = [1] * len(content_layers)\n",
    "\n",
    "# 최적화할 목표값 (style target) 계산\n",
    "# style_img를 VGG를 통과시켜서 각 레이어의 출력값을 계산\n",
    "# 변화 추적X\n",
    "# [A_r11, A_r21, ...] A.shape [b, c, h, w]\n",
    "# GramMatrix(A).shape [b, c, c]\n",
    "# detach() : 계산 그래프 분리(역전파 시 gradient 계산X)\n",
    "style_targets = [GramMatrix()(A).detach() for A in vgg(style_img, style_layers)]\n",
    "\n",
    "# 최적화 목표값(content targets)을 계산함.\n",
    "# 콘텐츠 이미지(content_image)를 VGG에 통과시켜 콘텐츠 레이어의 특징 맵을 추출하고 변화도 추적에서 제외(detach)했음.\n",
    "# content_image 또한 이미 .cuda() 또는 .to(device)로 GPU에 로드되어 있다고 가정합니다.\n",
    "content_targets = [A.detach() for A in vgg(content_image, content_layers)]\n",
    "\n",
    "# 최종적으로 사용할 모든 목표값 리스트를 정의함.\n",
    "targets = style_targets + content_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
