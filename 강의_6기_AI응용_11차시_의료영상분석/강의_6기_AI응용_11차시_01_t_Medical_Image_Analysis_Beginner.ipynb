{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "0c5hf3cDWSQQ",
        "outputId": "e0b58d56-3999-4c80-a0aa-592b7778d52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle API Token (kaggle.json) 파일을 선택하여 업로드해주세요.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Kaggle API Token 업로드 코드\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from google.colab import files\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 파일 업로드 대화 상자를 띄웁니다.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKaggle API Token (kaggle.json) 파일을 선택하여 업로드해주세요.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m uploaded = \u001b[43mfiles\u001b[49m.upload()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 업로드된 파일 이름을 확인합니다.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mkaggle.json\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m uploaded:\n",
            "\u001b[31mNameError\u001b[39m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "## Kaggle API Token 업로드 코드\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# 파일 업로드 대화 상자를 띄웁니다.\n",
        "print(\"Kaggle API Token (kaggle.json) 파일을 선택하여 업로드해주세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일 이름을 확인합니다.\n",
        "if 'kaggle.json' in uploaded:\n",
        "    print(\"kaggle.json 파일 업로드 완료.\")\n",
        "\n",
        "    # .kaggle 디렉토리를 생성하고 kaggle.json을 이동/복사합니다.\n",
        "    # Kaggle CLI가 파일을 찾을 수 있도록 표준 위치에 저장합니다.\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "    # API 키 파일에 대한 권한을 설정합니다 (보안을 위해 필수).\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    print(\"Kaggle 환경 설정 완료. 이제 !kaggle 명령어를 사용할 수 있습니다.\")\n",
        "else:\n",
        "    print(\"'kaggle.json' 파일이 업로드되지 않았거나 파일명이 다릅니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "RAShGxmSWp29",
        "outputId": "d8d7a1d5-f1e6-457f-b70f-c61f11c84a85"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "========================================\n",
        "11주차 실습: 의료영상 분석 (초급)\n",
        "Medical Image Analysis with Chest X-Ray\n",
        "========================================\n",
        "\n",
        "데이터셋: Kaggle Chest X-Ray Pneumonia Dataset\n",
        "목표: ResNet18 Transfer Learning + Grad-CAM 기초\n",
        "\n",
        "실습 구성:\n",
        "1. 환경 설정\n",
        "2. DICOM 기초 이해\n",
        "3. 데이터셋 다운로드 및 탐색\n",
        "4. 데이터 전처리\n",
        "5. 모델 구성 (ResNet18)\n",
        "6. 모델 학습\n",
        "7. 성능 평가\n",
        "8. Grad-CAM 시각화\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSxqnABRXECK",
        "outputId": "3f773a22-27c7-4c4a-8bdf-1fab7fc6c12d"
      },
      "outputs": [],
      "source": [
        "# 섹션 1: 환경 설정 및 라이브러리 설치\n",
        "\n",
        "# 필요한 라이브러리 설치 (에러 방지를 위해 패키지 이름 수정 및 설치 명령어 분리)\n",
        "# grad-cam: Grad-CAM 시각화를 위한 라이브러리 (pytorch-grad-cam 대신 사용)\n",
        "# pydicom: DICOM 파일을 읽기 위한 라이브러리\n",
        "# opendatasets: Kaggle 데이터셋 다운로드용\n",
        "\n",
        "!pip install -q pydicom opendatasets\n",
        "!pip install -q grad-cam # pytorch-grad-cam 대신 grad-cam 설치\n",
        "\n",
        "# 기본 라이브러리 임포트\n",
        "import os  # 파일 및 디렉토리 관리\n",
        "import numpy as np  # 수치 계산\n",
        "import matplotlib.pyplot as plt  # 시각화\n",
        "from PIL import Image  # 이미지 처리\n",
        "import torch  # PyTorch 메인 라이브러리\n",
        "import torch.nn as nn  # 신경망 모듈\n",
        "import torch.optim as optim  # 최적화 알고리즘\n",
        "from torch.utils.data import Dataset, DataLoader  # 데이터 로딩\n",
        "import torchvision.transforms as transforms  # 이미지 변환\n",
        "from torchvision import models  # 사전학습된 모델\n",
        "from torchvision.models import ResNet18_Weights # 최신 가중치 로드 방식\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # 평가 지표\n",
        "import seaborn as sns  # 시각화 (confusion matrix용)\n",
        "import pydicom  # DICOM 파일 읽기\n",
        "# Grad-CAM 관련 라이브러리 임포트 (모듈명은 pytorch_grad_cam을 유지)\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# 랜덤 시드 고정 (재현 가능한 결과를 위해)\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)  # PyTorch 시드\n",
        "np.random.seed(SEED)  # NumPy 시드\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True # 결정적 알고리즘 사용\n",
        "    torch.backends.cudnn.benchmark = False   # 속도보다는 재현성 우선\n",
        "\n",
        "# GPU 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 디바이스: {device}\")\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ogPf3KyYVbZ",
        "outputId": "cf25388b-a5b5-40d3-a0b7-6d3e6d7f8323"
      },
      "outputs": [],
      "source": [
        "# 섹션 2: DICOM 기초 이해\n",
        "\n",
        "# DICOM이란?\n",
        "# Digital Imaging and Communications in Medicine\n",
        "# 의료영상의 표준 포맷으로, 이미지 데이터와 메타데이터(환자정보, 촬영정보 등)를 포함\n",
        "\n",
        "# 간단한 DICOM 구조 시각화\n",
        "print(\"\\nDICOM 파일 구조:\")\n",
        "print(\"┌─────────────────────┐\")\n",
        "print(\"│  DICOM File Header  │  ← 파일 식별자\")\n",
        "print(\"├─────────────────────┤\")\n",
        "print(\"│   Meta Information  │  ← 전송 구문 정보\")\n",
        "print(\"├─────────────────────┤\")\n",
        "print(\"│  Patient Info       │  ← 환자 정보\")\n",
        "print(\"│  Study Info         │  ← 검사 정보\")\n",
        "print(\"│  Series Info        │  ← 시리즈 정보\")\n",
        "print(\"│  Image Info         │  ← 영상 정보\")\n",
        "print(\"├─────────────────────┤\")\n",
        "print(\"│   Pixel Data        │  ← 실제 이미지 데이터\")\n",
        "print(\"└─────────────────────┘\")\n",
        "\n",
        "# 실제 DICOM 예제 (샘플 파일이 있다면)\n",
        "print(\"\\nDICOM 메타데이터 주요 항목:\")\n",
        "print(\"- PatientName: 환자 이름\")\n",
        "print(\"- PatientAge: 환자 나이\")\n",
        "print(\"- Modality: 촬영 방식 (X-Ray, CT, MRI 등)\")\n",
        "print(\"- WindowCenter/WindowWidth: 영상 밝기 조절 값\")\n",
        "print(\"- PixelData: 실제 이미지 픽셀 배열\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMGPQwixYVYs",
        "outputId": "a060dd85-d11b-4aa4-9280-abbbc8b0de0b"
      },
      "outputs": [],
      "source": [
        "# 섹션 3: 데이터셋 다운로드 및 탐색\n",
        "\n",
        "# Kaggle API 설정 (Kaggle 계정 필요)\n",
        "# Kaggle에서 API Token을 다운로드하여 업로드해야 함\n",
        "\n",
        "\n",
        "# Kaggle API 설정 및 데이터셋 다운로드\n",
        "try:\n",
        "    # files.upload() 대신 파일이 업로드되었다고 가정하고 셸 명령 실행\n",
        "    # (Colab 환경에서 블록킹 오류를 방지하기 위함)\n",
        "    if os.path.exists(\"kaggle.json\"):\n",
        "        from google.colab import files # files 모듈 임포트 유지\n",
        "\n",
        "        # Kaggle 디렉토리 생성 및 파일 이동\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "        # 데이터셋 다운로드\n",
        "        !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p ./data\n",
        "\n",
        "        # 압축 해제\n",
        "        !unzip -o -q ./data/chest-xray-pneumonia.zip -d ./data/\n",
        "\n",
        "        # 불필요한 파일/폴더 제거\n",
        "        !rm ./data/chest-xray-pneumonia.zip\n",
        "        !rm -rf ./data/__MACOSX\n",
        "\n",
        "        print(\"다운로드 완료!\")\n",
        "        data_dir = \"./data/chest_xray\"\n",
        "    else:\n",
        "        print(\"'kaggle.json' 파일을 찾을 수 없습니다. 파일을 업로드해주세요.\")\n",
        "        data_dir = \"./data/chest_xray\" # 경로 변수는 설정\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"다운로드 실패: {e}\")\n",
        "    print(\"   수동으로 데이터셋을 다운로드하여 업로드해주세요.\")\n",
        "    data_dir = \"./data/chest_xray\" # 실패하더라도 경로 변수는 설정\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWVDmt1zYVWE",
        "outputId": "a2bac661-defa-40f3-f84d-caab58c04a0f"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 구조 확인\n",
        "print(\"\\n데이터셋 구조:\")\n",
        "if os.path.exists(data_dir):\n",
        "    # TRAIN 디렉토리만 확인하여 경로 오류 방지\n",
        "    check_dir = os.path.join(data_dir, \"train\")\n",
        "    if os.path.exists(check_dir):\n",
        "        # TRAIN, TEST 디렉토리를 중심으로 구조 출력\n",
        "        for split in ['train', 'test']:\n",
        "            print(f\"  {split.upper()}/\")\n",
        "            for class_name in ['NORMAL', 'PNEUMONIA']:\n",
        "                class_path = os.path.join(data_dir, split, class_name)\n",
        "                if os.path.exists(class_path):\n",
        "                    files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "                    print(f\"    {class_name}/\")\n",
        "                    for file in files[:3]:  # 처음 3개만 표시\n",
        "                         print(f\"      {file}\")\n",
        "                    if len(files) > 3:\n",
        "                        print(f\"      ... (총 {len(files)}개 파일)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "kzhrunhUYVTe",
        "outputId": "fa3d3667-3e16-46a2-a1d9-070e9a5241da"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 통계\n",
        "if os.path.exists(os.path.join(data_dir, \"train/NORMAL\")):\n",
        "    train_normal = len(os.listdir(os.path.join(data_dir, \"train/NORMAL\")))\n",
        "    train_pneumonia = len(os.listdir(os.path.join(data_dir, \"train/PNEUMONIA\")))\n",
        "    test_normal = len(os.listdir(os.path.join(data_dir, \"test/NORMAL\")))\n",
        "    test_pneumonia = len(os.listdir(os.path.join(data_dir, \"test/PNEUMONIA\")))\n",
        "\n",
        "    print(\"\\n데이터셋 통계:\")\n",
        "    print(f\"   Train - NORMAL: {train_normal}장\")\n",
        "    print(f\"   Train - PNEUMONIA: {train_pneumonia}장\")\n",
        "    print(f\"   Test - NORMAL: {test_normal}장\")\n",
        "    print(f\"   Test - PNEUMONIA: {test_pneumonia}장\")\n",
        "\n",
        "    # 샘플 이미지 시각화를 위한 경로 유효성 검사\n",
        "    if train_normal > 0 and train_pneumonia > 0:\n",
        "        # 샘플 이미지 시각화\n",
        "        print(\"\\n샘플 이미지 확인:\")\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "\n",
        "        # Normal 샘플 3개\n",
        "        normal_path = os.path.join(data_dir, \"train/NORMAL\")\n",
        "        normal_images = [f for f in os.listdir(normal_path) if f.lower().endswith(('.jpeg', '.jpg', '.png'))][:3]\n",
        "        for i, img_name in enumerate(normal_images):\n",
        "            img = Image.open(os.path.join(normal_path, img_name))\n",
        "            axes[0, i].imshow(img, cmap='gray')\n",
        "            axes[0, i].set_title(f\"NORMAL - {img_name}\", fontsize=10)\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "        # Pneumonia 샘플 3개\n",
        "        pneumonia_path = os.path.join(data_dir, \"train/PNEUMONIA\")\n",
        "        pneumonia_images = [f for f in os.listdir(pneumonia_path) if f.lower().endswith(('.jpeg', '.jpg', '.png'))][:3]\n",
        "        for i, img_name in enumerate(pneumonia_images):\n",
        "            img = Image.open(os.path.join(pneumonia_path, img_name))\n",
        "            axes[1, i].imshow(img, cmap='gray')\n",
        "            axes[1, i].set_title(f\"PNEUMONIA - {img_name}\", fontsize=10)\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('sample_xray_images.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"샘플 이미지가 저장되었습니다: sample_xray_images.png\")\n",
        "    else:\n",
        "         print(\"\\n샘플 이미지를 시각화할 데이터가 부족합니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK2N0m23YVQ-",
        "outputId": "d8e3ba0c-ea32-40b2-b0ed-a3eecd032b3b"
      },
      "outputs": [],
      "source": [
        "# 섹션 4: 데이터 전처리 및 Dataset 클래스\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "# ResNet18은 ImageNet으로 사전학습되었으므로 동일한 정규화 사용\n",
        "print(\"\\n이미지 전처리 설정:\")\n",
        "print(\"   - 크기 조정: 224x224 (ResNet 입력 크기)\")\n",
        "print(\"   - RGB 변환: 흑백 → 컬러 (3채널)\")\n",
        "print(\"   - 텐서 변환 및 정규화\")\n",
        "\n",
        "# ImageNet의 평균 및 표준편차 (재사용을 위해 정의)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Train 용 전처리 (데이터 증강 포함)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
        "    transforms.Grayscale(num_output_channels=3),  # 흑백 이미지를 컬러(RGB)로 변환\n",
        "    transforms.RandomHorizontalFlip(p=0.3),  # (30% 확률로)랜덤 수평 뒤집기(좌우 반전) 데이터 증강\n",
        "    transforms.RandomRotation(degrees=10),   # +- 10 도 범위 내에서 회전\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD) #ImageNet 평균값, 표준편차로 정규화\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
        "    transforms.Grayscale(num_output_channels=3),  # 흑백 이미지를 컬러(RGB)로 변환\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD) #ImageNet 평균값, 표준편차로 정규화\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tJ5C24PYVOY"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset 클래스 정의\n",
        "class ChestXrayDataset(Dataset):\n",
        "    \"\"\"\n",
        "    흉부 X-Ray 데이터셋 클래스\n",
        "    NORMAL과 PNEUMONIA 두 클래스를 분류\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): 데이터 루트 디렉토리 경로\n",
        "            transform: 이미지 전처리 파이프라인\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir  # 데이터 경로\n",
        "        self.transform = transform  # 전처리 함수\n",
        "        self.images = []  # 이미지 경로 리스트\n",
        "        self.labels = []  # 라벨 리스트\n",
        "\n",
        "        # 클래스별 디렉토리에서 이미지 파일 경로 수집\n",
        "        # 0: NORMAL, 1: PNEUMONIA\n",
        "        classes = ['NORMAL', 'PNEUMONIA']\n",
        "        for label, class_name in enumerate(classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)  # 클래스 디렉토리\n",
        "            if os.path.exists(class_dir):\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    if img_name.lower().endswith(('.jpeg', '.jpg', '.png')):  # 이미지 파일만\n",
        "                        self.images.append(os.path.join(class_dir, img_name))  # 경로 저장\n",
        "                        self.labels.append(label)  # 라벨 저장\n",
        "            else:\n",
        "                 pass # 경로가 없으면 무시하고 넘어감\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"데이터셋 크기 반환\"\"\"\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        인덱스에 해당하는 이미지와 라벨 반환\n",
        "        Args:\n",
        "            idx: 데이터 인덱스\n",
        "        Returns:\n",
        "            image: 전처리된 이미지 텐서\n",
        "            label: 클래스 라벨 (0 or 1)\n",
        "        \"\"\"\n",
        "        img_path = self.images[idx]  # 이미지 경로\n",
        "        image = Image.open(img_path).convert('RGB')  # 이미지 로드 및 RGB 변환\n",
        "        label = self.labels[idx]  # 라벨\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)  # 전처리 적용\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgAFml3HYVKo"
      },
      "outputs": [],
      "source": [
        "# Dataset 및 DataLoader 생성\n",
        "train_dataset = ChestXrayDataset(\n",
        "    root_dir = os.path.join(data_dir, \"train\"),\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = ChestXrayDataset(\n",
        "    root_dir = os.path.join(data_dir, \"test\"),\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "# 데이터가 없는 경우를 대비하여 조건문 추가\n",
        "if len(train_dataset) == 0:\n",
        "    print(\"학습 데이터셋이 비어있습니다. 이후 학습 및 평가 단계를 건너뛸 수 있습니다.\")\n",
        "\n",
        "# DataLoader 생성 (배치 단위로 데이터 로딩)\n",
        "batch_size = 32  # 한 번에 처리할 이미지 개수\n",
        "num_workers = 2  # 병렬 처리 워커 수 (Colab 환경에 적합)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuZtAQATgzgb",
        "outputId": "a187771a-c023-4e6a-9d21-de4df52642dc"
      },
      "outputs": [],
      "source": [
        "print(f\"   Train 데이터: {len(train_dataset)}장\")\n",
        "print(f\"   Test 데이터: {len(test_dataset)}장\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Train batches: {len(train_loader)}개\")\n",
        "print(f\"   Test batches: {len(test_loader)}개\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKKyfI2VhEfi",
        "outputId": "9cd3c459-f2b0-4c75-e8ad-641ff21fa597"
      },
      "outputs": [],
      "source": [
        "# 섹션 5: 모델 구성 (ResNet18 Transfer Learning)\n",
        "\n",
        "print(\"\\nTransfer Learning이란?\")\n",
        "print(\"   - 대규모 데이터셋(ImageNet)으로 사전학습된 모델을 활용\")\n",
        "print(\"   - 마지막 분류층(FC)만 우리 문제에 맞게 교체\")\n",
        "\n",
        "# (사전 학습된) 모델 로드\n",
        "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# 모델 구조 확인\n",
        "print(\"\\nResNet18 기본 구조:\")\n",
        "print(f\"   - 입력: 224x224x3 RGB 이미지\")\n",
        "print(f\"   - 출력: 1000개 클래스 (ImageNet)\")\n",
        "\n",
        "# 마지막 fc layer 교체 (1000 >> 2개 (정상, 폐렴 환자))\n",
        "num_features = model.fc.in_features # fc layer 입력 특징 개수\n",
        "model.fc = nn.Linear(num_features, 2)  # 2개 클래스 변경\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "#수정된 모델 최종 층\n",
        "# Linear(in_features=512, out_features=2, bias=True)\n",
        "model.fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PLPBxnTViLii",
        "outputId": "d63bb8ef-2a93-4191-f8c4-96950a0d7f50"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "\n",
        "# 손실함수\n",
        "criterion = nn.CrossEntropyLoss() # 다중 클래스 분류용 손실함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "print(\"\\n학습 설정:\")\n",
        "print(f\"   - 손실 함수: CrossEntropyLoss\")\n",
        "print(f\"   - 옵티마이저: Adam\")\n",
        "print(f\"   - 학습률: 0.0001\")\n",
        "print(f\"   - 에폭 수: 5\")\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    \"\"\"\n",
        "    모델 학습 함수\n",
        "    Args:\n",
        "        model: 학습할 모델\n",
        "        train_loader: 학습 데이터 로더\n",
        "        criterion: 손실 함수\n",
        "        optimizer: 옵티마이저\n",
        "        num_epochs: 학습 에폭 수\n",
        "    Returns:\n",
        "        train_losses: 에폭별 학습 손실\n",
        "        train_accuracies: 에폭별 학습 정확도\n",
        "    \"\"\"\n",
        "    train_losses = []  # 에폭별 손실 저장\n",
        "    train_accuracies = []  # 에폭별 정확도 저장\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # 학습 모드\n",
        "        running_loss = 0.0  # 현재 에폭 손실 누적\n",
        "        correct = 0  # 정답 개수\n",
        "        total = 0  # 전체 샘플 개수\n",
        "\n",
        "        # 배치별 학습\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)  # 이미지를 GPU로\n",
        "            labels = labels.to(device)  # 라벨을 GPU로\n",
        "\n",
        "            # Forward pass (순전파)\n",
        "            outputs = model(images)  # 모델 예측\n",
        "            loss = criterion(outputs, labels)  # 손실 계산\n",
        "\n",
        "            # Backward pass (역전파)\n",
        "            optimizer.zero_grad()  # 기울기 초기화\n",
        "            loss.backward()  # 역전파\n",
        "            optimizer.step()  # 가중치 업데이트\n",
        "\n",
        "            # 통계 계산\n",
        "            running_loss += loss.item()  # 손실 누적\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 예측 클래스\n",
        "            total += labels.size(0)  # 전체 샘플 수\n",
        "            correct += (predicted == labels).sum().item()  # 정답 개수\n",
        "\n",
        "            # 100 배치마다 진행상황 출력 (데이터셋 크기 고려)\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"   Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                      f\"Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                      f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # 에폭 통계\n",
        "        epoch_loss = running_loss / len(train_loader)  # 평균 손실\n",
        "        epoch_acc = 100 * correct / total  # 정확도\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}] 완료:\")\n",
        "        print(f\"   평균 Loss: {epoch_loss:.4f}\")\n",
        "        print(f\"   정확도: {epoch_acc:.2f}%\\n\")\n",
        "\n",
        "    return train_losses, train_accuracies\n",
        "\n",
        "# 모델 학습 실행 (데이터가 있을 경우에만)\n",
        "if len(train_dataset) > 0:\n",
        "    print(\"\\n학습 시작!\\n\")\n",
        "    num_epochs = 5  # 초급 실습이므로 5 에폭\n",
        "    train_losses, train_accuracies = train_model(\n",
        "        model, train_loader, criterion, optimizer, num_epochs\n",
        "    )\n",
        "    print(\"\\n학습 완료!\")\n",
        "\n",
        "    # 학습 곡선 시각화\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Loss 그래프\n",
        "    axes[0].plot(range(1, num_epochs+1), train_losses, 'b-o', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy 그래프\n",
        "    axes[1].plot(range(1, num_epochs+1), train_accuracies, 'g-o', linewidth=2)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    axes[1].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"학습 곡선이 저장되었습니다: training_curves.png\")\n",
        "else:\n",
        "    print(\"\\n학습 데이터셋이 비어있어 학습을 건너뜁니다.\")\n",
        "    train_losses = []\n",
        "    train_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9JupkNVxuSt"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "\n",
        "# 평가 함수\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    테스트 데이터로 모델 평가\n",
        "    Args:\n",
        "        model: 평가할 모델\n",
        "        test_loader: 테스트 데이터 로더\n",
        "    Returns:\n",
        "        accuracy: 정확도\n",
        "        all_labels: 실제 라벨\n",
        "        all_predictions: 예측 라벨\n",
        "    \"\"\"\n",
        "    model.eval()  # 평가 모드\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []  # 실제 라벨 저장\n",
        "    all_predictions = []  # 예측 라벨 저장\n",
        "\n",
        "    with torch.no_grad():  # 기울기 계산 비활성화\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)  # 예측\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 최대값 인덱스\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # CPU로 이동하여 저장\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy, all_labels, all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "roK2rUZ538Rv",
        "outputId": "cf71dac9-1df4-422e-d2ad-6b851dd8e9fd"
      },
      "outputs": [],
      "source": [
        "# 평가 실행 (테스트 데이터가 있고, 학습이 진행되었다고 가정)\n",
        "test_accuracy = 0.0\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "if len(test_dataset) > 0 and len(train_dataset) > 0:\n",
        "    print(\"\\n테스트 데이터 평가 중...\")\n",
        "    test_accuracy, true_labels, pred_labels = evaluate_model(model, test_loader)\n",
        "    print(f\"\\n테스트 정확도: {test_accuracy:.2f}%\")\n",
        "\n",
        "    # Confusion Matrix 생성\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    print(\"\\n Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Confusion Matrix 시각화\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['NORMAL', 'PNEUMONIA'],\n",
        "                yticklabels=['NORMAL', 'PNEUMONIA'],\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Confusion Matrix 저장: confusion_matrix.png\")\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    class_names = ['NORMAL', 'PNEUMONIA']\n",
        "    print(classification_report(true_labels, pred_labels, target_names=class_names, zero_division=0))\n",
        "else:\n",
        "    print(\"\\n테스트 데이터셋이 비어있거나 학습이 진행되지 않아 평가를 건너뜁니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "cByisGj24SLE",
        "outputId": "95d3ae4e-967f-431c-b5bb-aebebe23b78f"
      },
      "outputs": [],
      "source": [
        "# 섹션 8: Grad-CAM 시각화 (XAI)\n",
        "\n",
        "\n",
        "if len(test_dataset) > 0 and len(train_dataset) > 0:\n",
        "\n",
        "    print(\"\\nGrad-CAM이란?\")\n",
        "    print(\"   - Gradient-weighted Class Activation Mapping\")\n",
        "    print(\"   - 모델이 어느 부분을 보고 판단했는지 시각화\")\n",
        "    print(\"   - 의료 AI의 신뢰성 향상에 필수\")\n",
        "\n",
        "    # Grad-CAM 설정\n",
        "    target_layers = [model.layer4[-1]]  # ResNet18의 마지막 conv layer\n",
        "    grad_cam = GradCAM(model=model, target_layers=target_layers) # grad_cam 변수명으로 변경 (기존 cam과 충돌 방지)\n",
        "\n",
        "    # 테스트 이미지 선택 (각 클래스별 1장씩)\n",
        "    def get_sample_images(test_dataset, num_samples=1):\n",
        "        \"\"\"각 클래스에서 샘플 이미지 추출\"\"\"\n",
        "        samples = {'NORMAL': [], 'PNEUMONIA': []}\n",
        "\n",
        "        for idx in range(len(test_dataset)):\n",
        "            img_tensor, label = test_dataset[idx]\n",
        "            class_name = 'NORMAL' if label == 0 else 'PNEUMONIA'\n",
        "\n",
        "            if len(samples[class_name]) < num_samples:\n",
        "                # 원본 이미지도 함께 저장 (경로를 통해 로드)\n",
        "                # TestDataset은 경로를 반환하지 않지만, 임시로 로드한 후 원본 경로를 찾을 수 없으므로\n",
        "                # 여기서는 Dataset 클래스에서 직접 경로를 가져와야 함 (단, test_dataset은 경로를 저장하지 않음)\n",
        "                # 이를 위해 임시로 test_dataset을 ChestXrayDatasetAdvanced처럼 return_path=True로 구현하는 것이 이상적이나,\n",
        "                # 초급 실습의 단순성을 위해, 여기서는 경로를 직접 로드할 수 있도록 test_dataset의 내부 images 리스트를 사용합니다.\n",
        "\n",
        "                # 주의: test_dataset이 random_split으로 생성된 경우 이 방식은 작동하지 않으나,\n",
        "                # 초급 코드는 random_split을 사용하지 않으므로, images 리스트를 사용합니다.\n",
        "\n",
        "                # 안전한 방법: Dataset 클래스 내부에 경로를 저장했는지 확인하고 사용\n",
        "                if hasattr(test_dataset, 'images'):\n",
        "                    img_path = test_dataset.images[idx]\n",
        "                    orig_img = Image.open(img_path).convert('RGB')\n",
        "                    samples[class_name].append((img_tensor, label, orig_img))\n",
        "\n",
        "            if all(len(v) >= num_samples for v in samples.values()):\n",
        "                break\n",
        "\n",
        "        return samples\n",
        "\n",
        "    # 샘플 이미지 가져오기\n",
        "    print(\"\\n샘플 이미지 선택 중...\")\n",
        "    sample_images = get_sample_images(test_dataset, num_samples=1)\n",
        "\n",
        "    # Grad-CAM 적용 및 시각화\n",
        "    # 샘플이 최소한 1개라도 있어야 시각화 진행\n",
        "    if sample_images['NORMAL'] and sample_images['PNEUMONIA']:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "        for row, (class_name, samples) in enumerate(sample_images.items()):\n",
        "            # 각 클래스에서 첫 번째 샘플을 사용\n",
        "            img_tensor, label, orig_img = samples[0]\n",
        "\n",
        "            # 모델 예측\n",
        "            model.eval()\n",
        "            input_tensor = img_tensor.unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "                pred_prob = torch.softmax(output, dim=1) # (batch_size, class)\n",
        "                # (1, 10) >> 이미지 1장, 클래스 10개\n",
        "                pred_class = torch.argmax(pred_prob, dim=1).item()\n",
        "                confidence = pred_prob[0][pred_class].item() * 100\n",
        "                # pred_prob[0] : 확률리스트 [0.1, 0.8, 0.05,...]\n",
        "                # [pred_class] : 예측 클래스의 index 1\n",
        "\n",
        "            # Grad-CAM 생성\n",
        "            targets = [ClassifierOutputTarget(pred_class)]\n",
        "            grayscale_cam = grad_cam(input_tensor=input_tensor, targets=targets)\n",
        "            # grad_cam 계산 (1,224,224) (b,h,w) 크기의 히트맵 (0-1 범위)\n",
        "            grayscale_cam = grayscale_cam[0, :]\n",
        "            # 0 : batch_size >> 1개, \":\" 나머지 차원 (24,24) 그대로 가져와 (224,224) (h,w)\n",
        "\n",
        "\n",
        "            # 원본 이미지를 numpy 배열로 변환\n",
        "            orig_img_resized = orig_img.resize((224, 224))\n",
        "            rgb_img = np.array(orig_img_resized, dtype=np.float32) / 255.0\n",
        "            # 0-255 범위 >> 0~1 범위로 정규화(실수 변환 후)\n",
        "\n",
        "            # CAM 오버레이\n",
        "            cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "            # 시각화\n",
        "            # 1. 원본 이미지\n",
        "            axes[row, 0].imshow(orig_img_resized)\n",
        "            axes[row, 0].set_title(f'{class_name} - Original', fontsize=12, fontweight='bold')\n",
        "            axes[row, 0].axis('off')\n",
        "\n",
        "            # 2. Grad-CAM Heatmap\n",
        "            axes[row, 1].imshow(grayscale_cam, cmap='jet')\n",
        "            axes[row, 1].set_title('Grad-CAM Heatmap', fontsize=12, fontweight='bold')\n",
        "            axes[row, 1].axis('off')\n",
        "\n",
        "            # 3. 오버레이\n",
        "            axes[row, 2].imshow(cam_image)\n",
        "            pred_name = 'NORMAL' if pred_class == 0 else 'PNEUMONIA'\n",
        "            axes[row, 2].set_title(f'Prediction: {pred_name}\\nConfidence: {confidence:.1f}%',\n",
        "                                  fontsize=12, fontweight='bold')\n",
        "            axes[row, 2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('gradcam_results.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"Grad-CAM 결과 저장: gradcam_results.png\")\n",
        "    else:\n",
        "        print(\"\\nGrad-CAM 시각화를 위한 NORMAL/PNEUMONIA 샘플이 부족합니다.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n학습이 진행되지 않았거나 테스트 데이터셋이 비어있어 Grad-CAM을 건너뜁니다.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpF8ASFd7XTj",
        "outputId": "d13cc540-36e8-4981-add9-727180265e2c"
      },
      "outputs": [],
      "source": [
        "# 최종 요약\n",
        "\n",
        "print(f\"   1. 데이터셋: Chest X-Ray Pneumonia\")\n",
        "print(f\"   2. 학습 데이터: {len(train_dataset)}장\")\n",
        "print(f\"   3. 테스트 데이터: {len(test_dataset)}장\")\n",
        "print(f\"   4. 모델: ResNet18 Transfer Learning\")\n",
        "print(f\"   5. 학습 에폭: {5 if len(train_dataset) > 0 else 0}\")\n",
        "print(f\"   6. 최종 테스트 정확도: {test_accuracy:.2f}%\")\n",
        "print(f\"\\n생성된 파일:\")\n",
        "if len(train_dataset) > 0:\n",
        "    print(f\"   - sample_xray_images.png\")\n",
        "    print(f\"   - training_curves.png\")\n",
        "    print(f\"   - confusion_matrix.png\")\n",
        "    print(f\"   - gradcam_results.png\")\n",
        "else:\n",
        "    print(\"   (학습이 진행되지 않아 파일이 생성되지 않았습니다.)\")\n",
        "print(\"\\n다음 단계:\")\n",
        "print(\"   - 중고급 실습에서 더 고급 기법 학습\")\n",
        "print(\"   - 모델 성능 개선 실험\")\n",
        "print(\"   - 다양한 XAI 기법 탐색\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtXr4v97XKH",
        "outputId": "7873cf4f-9c51-46d3-dcfe-d00455852905"
      },
      "outputs": [],
      "source": [
        "# [기초 실습]\n",
        "players = {1: \"drwill\", 2: \"doosan\",3:\"rokey\", 4:\"son\"}\n",
        "players[1]\n",
        "players[1] = \"gang-in\"\n",
        "players"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
