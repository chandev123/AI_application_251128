{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "zUjTuQmV_ZFz",
        "outputId": "d2ea0b4c-a975-44ce-f299-30e757033eab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n11주차 실습: 의료영상 분석 (중고급)\\nAdvanced Medical Image Analysis with Chest X-Ray\\n\\n데이터셋: Kaggle Chest X-Ray Pneumonia Dataset\\n목표: 고급 Transfer Learning + 성능 최적화 + 심화 XAI\\n\\n실습 구성:\\n1. 환경 설정 및 유틸리티 함수\\n2. DICOM 고급 분석\\n3. 데이터셋 준비 (Train/Val/Test 분리)\\n4. 고급 데이터 증강 및 전처리\\n5. ResNet18 모델 + Early Stopping + LR Scheduler\\n6. 학습 및 검증\\n7. 심화 평가 (ROC-AUC, Precision-Recall)\\n8. 고급 Grad-CAM 분석 및 비교\\n9. 모델 저장 및 성능 보고서\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "\"\"\"\n",
        "11주차 실습: 의료영상 분석 (중고급)\n",
        "Advanced Medical Image Analysis with Chest X-Ray\n",
        "\n",
        "데이터셋: Kaggle Chest X-Ray Pneumonia Dataset\n",
        "목표: 고급 Transfer Learning + 성능 최적화 + 심화 XAI\n",
        "\n",
        "실습 구성:\n",
        "1. 환경 설정 및 유틸리티 함수\n",
        "2. DICOM 고급 분석\n",
        "3. 데이터셋 준비 (Train/Val/Test 분리)\n",
        "4. 고급 데이터 증강 및 전처리\n",
        "5. ResNet18 모델 + Early Stopping + LR Scheduler\n",
        "6. 학습 및 검증\n",
        "7. 심화 평가 (ROC-AUC, Precision-Recall)\n",
        "8. 고급 Grad-CAM 분석 및 비교\n",
        "9. 모델 저장 및 성능 보고서\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Kaggle API Token 업로드 코드\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# 파일 업로드 대화 상자를 띄웁니다.\n",
        "print(\"Kaggle API Token (kaggle.json) 파일을 선택하여 업로드해주세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일 이름을 확인합니다.\n",
        "if 'kaggle.json' in uploaded:\n",
        "    print(\"'kaggle.json' 파일 업로드 완료.\")\n",
        "\n",
        "    # .kaggle 디렉토리를 생성하고 kaggle.json을 이동/복사합니다.\n",
        "    # Kaggle CLI가 파일을 찾을 수 있도록 표준 위치에 저장합니다.\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "    # API 키 파일에 대한 권한을 설정합니다 (보안을 위해 필수).\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    print(\"Kaggle 환경 설정 완료. 이제 !kaggle 명령어를 사용할 수 있습니다.\")\n",
        "else:\n",
        "    print(\"'kaggle.json' 파일이 업로드되지 않았거나 파일명이 다릅니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "65WdFb3r_4NZ",
        "outputId": "557fe278-6f4e-45db-9928-2d0d84191e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API Token (kaggle.json) 파일을 선택하여 업로드해주세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1abb5baa-be1f-4d55-ad52-5e25262f2899\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1abb5baa-be1f-4d55-ad52-5e25262f2899\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "'kaggle.json' 파일이 업로드되지 않았거나 파일명이 다릅니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 1: 환경 설정 및 고급 라이브러리\n",
        "\n",
        "# 필요한 라이브러리 설치 (에러 방지를 위해 분리 및 이름 수정)\n",
        "\n",
        "# pydicom 설치\n",
        "!pip install -q pydicom\n",
        "# pytorch-grad-cam 대신 pypi에 등록된 'grad-cam'을 설치하도록 수정\n",
        "!pip install -q grad-cam opendatasets scikit-plot"
      ],
      "metadata": {
        "id": "XjKzmPeZ_8Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 라이브러리\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd  # 결과 분석용\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time  # 학습 시간 측정\n",
        "import json  # 설정 저장용\n",
        "from datetime import datetime  # 타임스탬프\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# random_split을 사용하기 위해 import\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "# 모델 가중치 로드 시 호환성 문제 해결을 위해 Weights 사용\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "# 평가 지표\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    roc_curve, auc, precision_recall_curve,\n",
        "    f1_score, accuracy_score, precision_score,\n",
        "    recall_score, roc_auc_score, average_precision_score)\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NudGGUOF_8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DICOM 처리\n",
        "import pydicom\n",
        "\n",
        "# Grad-CAM (패키지 이름은 'grad-cam'으로 설치했으나, 내부 모듈명은 'pytorch_grad_cam'을 유지)\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
      ],
      "metadata": {
        "id": "aIv2wyxQ_8J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 시드 고정 (재현성)\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"모든 난수 생성기의 시드를 고정하는 함수\"\"\"\n",
        "    torch.manual_seed(seed)  # PyTorch CPU\n",
        "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
        "    torch.cuda.manual_seed_all(seed)  # Multi-GPU\n",
        "    np.random.seed(seed)  # NumPy\n",
        "    # CuDNN 설정은 모델 학습 속도에 영향을 줄 수 있으나, 재현성을 위해 결정론적 모드를 활성화\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n사용 디바이스: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA 버전: {torch.version.cuda}\")\n",
        "print(f\"   PyTorch 버전: {torch.__version__}\")\n",
        "\n",
        "# 실험 설정 저장용 딕셔너리\n",
        "experiment_config = {\n",
        "    'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'device': str(device),\n",
        "    'pytorch_version': torch.__version__,\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9eYdKIm_8MR",
        "outputId": "a8b60e3f-0a2a-4cab-bc4e-7a97b88d23b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "사용 디바이스: cuda\n",
            "   GPU: NVIDIA L4\n",
            "   CUDA 버전: 12.6\n",
            "   PyTorch 버전: 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [Bact to the Basic]\n",
        "# print(datetime.now())\n",
        "# print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "metadata": {
        "id": "NbfQR6JPAc0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DICOM 고급 분석\n",
        "\n",
        "def analyze_dicom_metadata(dicom_path):\n",
        "    return {\"Message\": \"Not a DICOM file in this dataset\"}\n",
        "\n",
        "# DICOM 시각화 함수 (Window Level/Width 적용)\n",
        "def visualize_dicom_with_windowing(dicom_path, window_center=None, window_width=None):\n",
        "    \"\"\"\n",
        "    DICOM 이미지를 Window Level/Width를 적용하여 시각화\n",
        "    Args:\n",
        "        dicom_path: DICOM 파일 경로\n",
        "        window_center: 윈도우 중심값 (밝기)\n",
        "        window_width: 윈도우 폭 (대비)\n",
        "    \"\"\"\n",
        "    # 이 데이터셋은 JPEG 파일이므로 실제 DICOM 로직은 실행되지 않음\n",
        "    return None, {'Message': 'Not a DICOM file in this dataset'}\n",
        "\n",
        "print(\"\\nDICOM 분석 개념:\")\n",
        "print(\"   Window Level (밝기): 관심 영역의 중심 값\")\n",
        "# Window Level (밝기): 어디를 중심으로 보지? (보고자 하는 것의 평균 밝기)\n",
        "# > 밝기 조절 (명도)\n",
        "\n",
        "print(\"   Window Width (대비): 표시할 픽셀값 범위\")\n",
        "# Window Width (대비) 얼마나 넓은 범위를 볼 것인가\n",
        "# contrast 조절 (대비)\n",
        "# 폭이 좁으면? 명암 대비가 커져요 >> 흑백이 뚜렷해짐 (구조가 비슷한 거 구별 용이)\n",
        "# 폭이 넓으면? 명암 대비가 부드러워져요 (다양한 조직 한번에 볼 수 있어)\n",
        "print(\"   → 폐 조직: WL=-600, WW=1500\")\n",
        "print(\"   → 연조직: WL=40, WW=400\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAWp1HNeAhm5",
        "outputId": "4898e339-9414-4e98-881c-be77c0d3db0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DICOM 분석 개념:\n",
            "   Window Level (밝기): 관심 영역의 중심 값\n",
            "   Window Width (대비): 표시할 픽셀값 범위\n",
            "   → 폐 조직: WL=-600, WW=1500\n",
            "   → 연조직: WL=40, WW=400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HU (Housefield Unit) : CT 촬영한 원본 데이터 (-1000~3000)\n",
        "- 이 4000 정도 범위를 가진 색상을 화면 상에서 보이게 해야 함\n",
        "- 화면 상 보이는 색상은 0(검정색)부터 255(흰색) 임\n",
        "- 여기서 문제 발생. HU정보(4000개)를 256개의 색상으로 표현해야 함\n",
        "- 다 보여 줄 수 없으니깐 일부만 잘라서 보여줘야 함. 그 자른 범위의 크기가 바로 Window Width(WW) 임.\n",
        "- 폭이 작다는 의미는 예로 들어 HU를 50-100 까지 설정하면 조금만 바뀌여도 아주 작은 차이만 있어도 색이 심하게 변함\n",
        "- 검정색-흰색의 변화가 급발진 > 대비(contrast) 가 크다\n",
        "- 비슷비슷하게 생긴 즉 구조가 비슷한 간이나 종양 미세한 차이 구분할 때 유리\n",
        "- 반대로 폭을 넓게 잡으면 예를 들어 HU를 -1000~1000 일 경우, 2000개의 범위를 256개에 억지로 구겨 넣는 효과, 따라서 HU가 10, 20, 30 변해도 색깔 변화가 거의 없음\n",
        "- 색변화가 거의 없고, 즉 대비(contrast) 가 낮고 전체적으로 뿌옇게 보임\n",
        "- 따라서 뼈(하얀색), 폐(검은색) 처럼 성격이 아주 다른 것 한번에 볼 때 사용"
      ],
      "metadata": {
        "id": "RwImWyxEK6k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 3: 데이터셋 다운로드 및 준비\n",
        "\n",
        "\n",
        "# Kaggle 데이터셋 다운로드\n",
        "\n",
        "# Colab에서 kaggle.json 업로드는 수동으로 이미 했다고 가정하고\n",
        "# 자동 다운로드 및 압축 해제 코드만 실행\n",
        "try:\n",
        "    # Colab에서 files.upload() 대신 셸 명령어로 파일 처리 (사용자 업로드 가정)\n",
        "    if os.path.exists(\"kaggle.json\"):\n",
        "        from google.colab import files # files.upload()가 없어도 files 모듈은 import 필요\n",
        "\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "        print(\"\\n⏳ 다운로드 중... (약 2-3분 소요)\")\n",
        "        # -p ./data : 다운로드 경로를 ./data로 지정\n",
        "        !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p ./data\n",
        "        # -o: 덮어쓰기, -q: 조용히 실행, -d: 압축 해제 경로\n",
        "        !unzip -o -q ./data/chest-xray-pneumonia.zip -d ./data/\n",
        "\n",
        "        # 불필요한 파일/폴더 제거\n",
        "        !rm ./data/chest-xray-pneumonia.zip\n",
        "        !rm -rf ./data/__MACOSX\n",
        "\n",
        "        print(\"다운로드 완료!\")\n",
        "        data_dir = \"./data/chest_xray\"\n",
        "    else:\n",
        "        print(\"'kaggle.json' 파일이 없습니다. 수동으로 업로드하거나 이전 셀을 확인하세요.\")\n",
        "        data_dir = \"./data/chest_xray\" # 경로 변수는 설정\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"다운로드 실패: {e}\")\n",
        "    data_dir = \"./data/chest_xray\"\n",
        "\n",
        "# 데이터 경로 설정 및 유효성 검사\n",
        "if not os.path.exists(os.path.join(data_dir, 'train')):\n",
        "    print(f\"{data_dir} 경로에 'train' 폴더가 없습니다. 데이터셋 다운로드/경로를 확인하세요.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBtxJ2hICe2D",
        "outputId": "622bd2be-eac4-48a8-9fa3-f334f181f42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ 다운로드 중... (약 2-3분 소요)\n",
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 통계 분석\n",
        "def analyze_dataset_distribution(data_dir):\n",
        "    \"\"\"데이터셋의 클래스별 분포 분석\"\"\"\n",
        "    stats = {}\n",
        "\n",
        "    # Kaggle 데이터셋은 train, test, val 폴더로 구성되어 있음\n",
        "    for split in ['train', 'test', 'val']:\n",
        "        split_path = os.path.join(data_dir, split)\n",
        "        if os.path.exists(split_path):\n",
        "            stats[split] = {}\n",
        "            for class_name in ['NORMAL', 'PNEUMONIA']:\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                if os.path.exists(class_path):\n",
        "                    # 이미지 파일만 카운트\n",
        "                    count = len([f for f in os.listdir(class_path)\n",
        "                                if f.lower().endswith(('.jpeg', '.jpg', '.png'))])\n",
        "                    stats[split][class_name] = count\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "Pf3jJHtuOlZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분포 확인\n",
        "analyze_dataset_distribution(data_dir)"
      ],
      "metadata": {
        "id": "CW4CIgxEQWzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_stats = analyze_dataset_distribution(data_dir)\n",
        "\n",
        "pd.DataFrame(dataset_stats).T\n",
        "df_stats = pd.DataFrame(dataset_stats).T\n",
        "df_stats"
      ],
      "metadata": {
        "id": "5DZJe9MlQabw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 불균형 확인\n",
        "if 'train' in dataset_stats and 'NORMAL' in dataset_stats['train'] and 'PNEUMONIA' in dataset_stats['train']:\n",
        "    train_normal = dataset_stats['train']['NORMAL']\n",
        "    train_pneumonia = dataset_stats['train']['PNEUMONIA']\n",
        "    if train_normal > 0:\n",
        "        imbalance_ratio = train_pneumonia / train_normal\n",
        "        print(f\"\\n클래스 불균형 비율: {imbalance_ratio:.2f}:1 (PNEUMONIA:NORMAL)\")\n",
        "        if imbalance_ratio > 2:\n",
        "            print(\"   → 심각한 불균형! 가중치 적용 고려 필요\")\n",
        "    else:\n",
        "        imbalance_ratio = 0\n",
        "        print(\"Train/NORMAL 데이터가 0개입니다.\")\n",
        "else:\n",
        "    imbalance_ratio = 0\n",
        "    print(\"Train 데이터셋 통계를 확인할 수 없습니다. 데이터 경로를 확인하세요.\")"
      ],
      "metadata": {
        "id": "POH5McNaRDD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 4: 고급 데이터 증강 및 전처리\n",
        "\n",
        "\n",
        "print(\"\\n고급 증강 기법:\")\n",
        "print(\"   1. RandomHorizontalFlip: 좌우 반전\")\n",
        "print(\"   2. RandomRotation: 회전 (±15도)\")\n",
        "print(\"   3. RandomAffine: 이동 및 스케일링\")\n",
        "print(\"   4. ColorJitter: 밝기/대비 조정\")\n",
        "print(\"   5. GaussianBlur: 가우시안 블러 (노이즈 내성)\")\n",
        "\n",
        "# ImageNet의 평균 및 표준편차 (전역 변수로 정의)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Train용 고급 증강\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # 약간 크게 리사이즈\n",
        "    transforms.RandomCrop((224, 224)),  # 무작위 크롭 (224x224)\n",
        "    transforms.Grayscale(num_output_channels=3),  # RGB 변환\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # 50% 확률 좌우 반전\n",
        "    transforms.RandomRotation(degrees=15),  # ±15도 회전\n",
        "    transforms.RandomAffine(\n",
        "        degrees=0,  # 회전은 위에서 처리\n",
        "        translate=(0.1, 0.1),  # 10% 범위 이동\n",
        "        scale=(0.9, 1.1),  # 90%~110% 스케일\n",
        "    ),\n",
        "    transforms.ColorJitter(\n",
        "        brightness=0.2,  # 밝기 ±20%\n",
        "        contrast=0.2,    # 대비 ±20%\n",
        "    ),\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=3)  # 가우시안 블러\n",
        "    ], p=0.3),  # 30% 확률\n",
        "    transforms.ToTensor(),  # 텐서 변환\n",
        "    transforms.Normalize(\n",
        "        mean=IMAGENET_MEAN,  # ImageNet 평균\n",
        "        std=IMAGENET_STD    # ImageNet 표준편차\n",
        "    )\n",
        "])\n",
        "\n",
        "# Validation/Test용 전처리 (증강 없음)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # 크기만 조정\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=IMAGENET_MEAN,\n",
        "        std=IMAGENET_STD\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "M0Pj8WapR5aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset 클래스 (고급)\n",
        "class ChestXrayDatasetAdvanced(Dataset):\n",
        "    \"\"\"\n",
        "    고급 흉부 X-Ray 데이터셋 클래스\n",
        "    - 메타데이터 추출 옵션\n",
        "    - 클래스 가중치 계산\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None, return_path=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir: 데이터 루트 디렉토리\n",
        "            transform: 전처리 파이프라인\n",
        "            return_path: 이미지 경로도 함께 반환할지 여부\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.return_path = return_path\n",
        "        self.images = []  # 이미지 경로 리스트\n",
        "        self.labels = []  # 라벨 리스트\n",
        "\n",
        "        # 클래스별 이미지 수집\n",
        "        classes = ['NORMAL', 'PNEUMONIA']\n",
        "        for label, class_name in enumerate(classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    # 이미지 파일 확장자 체크\n",
        "                    if img_name.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
        "                        img_path = os.path.join(class_dir, img_name)\n",
        "                        self.images.append(img_path)\n",
        "                        self.labels.append(label)\n",
        "            else:\n",
        "                 # val 폴더는 없어도 됨 (train에서 분리하기 때문)\n",
        "                 if 'val' not in root_dir:\n",
        "                    # 경고 대신 메시지 출력\n",
        "                    pass\n",
        "\n",
        "\n",
        "        # 클래스 가중치 계산 (불균형 처리용) - 학습 데이터 로드 시에만 필요\n",
        "        self.class_weights = self._calculate_class_weights()\n",
        "\n",
        "    def _calculate_class_weights(self):\n",
        "        \"\"\"클래스 불균형을 보정하기 위한 가중치 계산\"\"\"\n",
        "        if not self.labels:\n",
        "            return torch.FloatTensor([1.0, 1.0]) # 데이터가 없으면 기본 가중치\n",
        "\n",
        "        labels_array = np.array(self.labels)\n",
        "        # bincount는 0부터 시작하는 정수 배열의 각 값의 출현 횟수를 셈\n",
        "        class_counts = np.bincount(labels_array)\n",
        "        total_samples = len(labels_array)\n",
        "        num_classes = len(class_counts)\n",
        "\n",
        "        # 역빈도 가중치: W_j = N / (C * N_j)\n",
        "        # N: 전체 샘플 수, C: 클래스 수, N_j: 클래스 j의 샘플 수\n",
        "        # 0으로 나누는 오류 방지: 0인 클래스 카운트는 매우 큰 가중치를 가짐\n",
        "        class_counts = np.where(class_counts == 0, 1, class_counts)\n",
        "        # class_counts == 0 데이터가 0개 이면 > 1로 바꿔줘(나눗셈 에러 방지)\n",
        "\n",
        "        weights = total_samples / (num_classes * class_counts)\n",
        "        return torch.FloatTensor(weights)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        # .convert('RGB')를 사용하여 3채널 이미지로 로드\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.return_path:\n",
        "            return image, label, img_path\n",
        "        return image, label\n",
        "\n",
        "# Dataset 생성\n",
        "print(\"\\n Dataset 생성 및 분리...\")"
      ],
      "metadata": {
        "id": "nlZTMJ4eS-BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 데이터 로드 (validation set 분리 전 전체 train 데이터)\n",
        "train_full_dataset = ChestXrayDatasetAdvanced(\n",
        "    root_dir=os.path.join(data_dir, \"train\"),\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "# Train을 Train/Val로 분리 (80:20)\n",
        "if len(train_full_dataset) > 0:\n",
        "    train_size = int(0.8 * len(train_full_dataset))\n",
        "    val_size = len(train_full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(\n",
        "        train_full_dataset,\n",
        "        [train_size, val_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "else:\n",
        "    # 데이터셋 로드 실패 시 빈 데이터셋 생성 (에러 방지)\n",
        "    train_dataset = []\n",
        "    val_dataset = []\n",
        "\n",
        "# Test 데이터 로드\n",
        "# Note: 이 데이터셋은 이미 test 폴더가 분리되어 있으므로 그대로 사용\n",
        "test_dataset = ChestXrayDatasetAdvanced(\n",
        "    root_dir=os.path.join(data_dir, \"test\"),\n",
        "    transform=test_transform,\n",
        "    return_path=True  # Grad-CAM용 경로 필요\n",
        ")\n",
        "\n",
        "print(f\"   Train: {len(train_dataset)}장\")\n",
        "print(f\"   Validation: {len(val_dataset)}장\")\n",
        "print(f\"   Test: {len(test_dataset)}장\")\n",
        "\n",
        "# 클래스 가중치 확인 (전체 Train 데이터 기준)\n",
        "class_weights = train_full_dataset.class_weights\n",
        "print(f\"\\n클래스 가중치: {class_weights.tolist()}\")"
      ],
      "metadata": {
        "id": "_0NXkHXKWVKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 생성\n",
        "batch_size = 32\n",
        "num_workers = 2 # Colab 환경에 적합한 워커 수\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,  # Train은 섞기\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True  # GPU 전송 속도 향상\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,  # Validation은 섞지 않음\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\nDataLoader 생성 완료:\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")\n",
        "print(f\"   Test batches: {len(test_loader)}\")\n",
        "\n",
        "experiment_config['batch_size'] = batch_size\n",
        "experiment_config['train_size'] = len(train_dataset)\n",
        "experiment_config['val_size'] = len(val_dataset)\n",
        "experiment_config['test_size'] = len(test_dataset)"
      ],
      "metadata": {
        "id": "9L7FIJ0_XZDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋이 비어있는 경우 학습을 건너뛰는 플래그\n",
        "is_trainable = len(train_dataset) > 0\n",
        "\n",
        "if is_trainable:\n",
        "\n",
        "    # 섹션 5: 모델 구성 + Early Stopping + LR Scheduler\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"섹션 5: ResNet18 모델 + 고급 학습 기법\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # ResNet18 모델 로드\n",
        "    print(\"\\nResNet18 Transfer Learning 모델 구성:\")\n",
        "    # ResNet18_Weights.IMAGENET1K_V1을 명시적으로 사용하여 최신 버전의 가중치 로드\n",
        "    # [Image of ResNet18 architecture]\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # FC layer 교체\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 2)  # 2 클래스\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(f\"FC layer: {num_features} → 2\")\n",
        "    print(f\"모델을 {device}로 이동\")\n",
        "\n",
        "    # 손실 함수 (클래스 가중치 적용)\n",
        "    # class_weights는 FloatTensor여야 하며, device에 이동시켜야 함\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    print(f\"\\n가중치 적용된 CrossEntropyLoss 사용\")\n",
        "\n",
        "    # 옵티마이저 (AdamW - Weight Decay 포함)\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=0.0001,\n",
        "        weight_decay=0.01  # L2 정규화\n",
        "    )\n",
        "    print(f\"옵티마이저: AdamW (lr=0.0001, weight_decay=0.01)\")\n",
        "\n",
        "    # Learning Rate Scheduler (성능 정체 시 LR 감소)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',  # validation loss 기준\n",
        "        factor=0.5,  # LR을 50%로 감소\n",
        "        patience=3,  # 3 에폭 동안 개선 없으면 감소\n",
        "\n",
        "    )\n",
        "    print(f\"LR Scheduler: ReduceLROnPlateau (patience=3)\")\n",
        "\n",
        "\n",
        "\n",
        "    # Early Stopping 클래스\n",
        "    class EarlyStopping:\n",
        "        \"\"\"\n",
        "        Early Stopping 구현 클래스\n",
        "        Validation loss가 개선되지 않으면 학습 조기 종료\n",
        "        \"\"\"\n",
        "        def __init__(self, patience=7, min_delta=0.001, verbose=True):\n",
        "            \"\"\"\n",
        "            Args:\n",
        "                patience: 몇 에폭 동안 개선이 없으면 종료할지\n",
        "                min_delta: 개선으로 인정할 최소 변화량\n",
        "                verbose: 로그 출력 여부\n",
        "            \"\"\"\n",
        "            self.patience = patience\n",
        "            self.min_delta = min_delta\n",
        "            self.verbose = verbose\n",
        "            self.counter = 0  # 개선 없는 에폭 카운터\n",
        "            self.best_loss = None  # 최고 성능\n",
        "            self.early_stop = False  # 종료 플래그\n",
        "            self.best_model = None  # 최고 모델 저장\n",
        "\n",
        "        def __call__(self, val_loss, model):\n",
        "            \"\"\"\n",
        "            Validation loss를 체크하고 Early Stop 여부 결정\n",
        "            \"\"\"\n",
        "            # val_loss가 텐서일 경우 .item()으로 스칼라 값 추출\n",
        "            if isinstance(val_loss, torch.Tensor):\n",
        "                val_loss = val_loss.item()\n",
        "\n",
        "            if self.best_loss is None:\n",
        "                # 첫 에폭\n",
        "                self.best_loss = val_loss\n",
        "                self.save_checkpoint(model)\n",
        "            elif val_loss > self.best_loss - self.min_delta:\n",
        "                # 개선되지 않음 (best_loss보다 min_delta만큼 작아지지 않음)\n",
        "                self.counter += 1\n",
        "                if self.verbose:\n",
        "                    print(f\"   EarlyStopping counter: {self.counter}/{self.patience}\")\n",
        "                if self.counter >= self.patience:\n",
        "                    self.early_stop = True\n",
        "            else:\n",
        "                # 개선됨 (val_loss < self.best_loss - self.min_delta)\n",
        "                if self.verbose:\n",
        "                    print(f\"Val loss 개선: {self.best_loss:.4f} → {val_loss:.4f}\")\n",
        "                self.best_loss = val_loss\n",
        "                self.save_checkpoint(model)\n",
        "                self.counter = 0\n",
        "\n",
        "        def save_checkpoint(self, model):\n",
        "            \"\"\"최고 성능 모델 저장\"\"\"\n",
        "            # 모델의 상태만 저장\n",
        "            self.best_model = model.state_dict().copy()\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "    print(f\"Early Stopping: patience=5\")\n",
        "\n",
        "    experiment_config['optimizer'] = 'AdamW'\n",
        "    experiment_config['learning_rate'] = 0.0001\n",
        "    experiment_config['weight_decay'] = 0.01\n",
        "    experiment_config['scheduler'] = 'ReduceLROnPlateau'\n",
        "    experiment_config['early_stopping_patience'] = 5\n",
        "\n",
        "    # 섹션 6: 학습 및 검증 (고급)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"섹션 6: 모델 학습 (Validation + Early Stopping)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 학습 함수 (Validation 포함)\n",
        "    def train_and_validate(model, train_loader, val_loader, criterion,\n",
        "                           optimizer, scheduler, early_stopping, num_epochs=20):\n",
        "        \"\"\"\n",
        "        학습 및 검증 함수 (고급)\n",
        "        \"\"\"\n",
        "        history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if early_stopping.early_stop:\n",
        "                break\n",
        "\n",
        "            epoch_start = time.time()\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            # ===== 학습 단계 =====\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # 통계\n",
        "                # loss.item()을 사용하여 평균 손실 계산\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                # 진행상황 출력 (100 배치마다)\n",
        "                if (batch_idx + 1) % 100 == 0: # 데이터셋이 크므로 100 배치마다 출력\n",
        "                    print(f\"   [Train] Batch [{batch_idx+1}/{len(train_loader)}] \"\n",
        "                          f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "            # 에폭 통계\n",
        "            avg_train_loss = train_loss / len(train_loader)\n",
        "            train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "            # ===== 검증 단계 =====\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    # random_split으로 분리된 dataset은 경로를 반환하지 않으므로 (images, labels) 형태\n",
        "                    images, labels = batch\n",
        "\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "            # 이력 저장\n",
        "            history['train_loss'].append(avg_train_loss)\n",
        "            history['train_acc'].append(train_accuracy)\n",
        "            history['val_loss'].append(avg_val_loss)\n",
        "            history['val_acc'].append(val_accuracy)\n",
        "            history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "            # 에폭 결과 출력\n",
        "            epoch_time = time.time() - epoch_start\n",
        "            print(f\"\\n{'─'*60}\")\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] 결과 (소요시간: {epoch_time:.1f}초)\")\n",
        "            print(f\"   Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
        "            print(f\"   Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
        "            print(f\"   Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "            # 최고 성능 체크\n",
        "            if val_accuracy > best_val_acc:\n",
        "                best_val_acc = val_accuracy\n",
        "                print(f\"새로운 최고 Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "            # LR Scheduler 업데이트\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            # Early Stopping 체크\n",
        "            early_stopping(avg_val_loss, model)\n",
        "\n",
        "        # 최고 모델 복원\n",
        "        if early_stopping.best_model is not None:\n",
        "            model.load_state_dict(early_stopping.best_model)\n",
        "            print(f\"\\n최고 성능 모델 복원 완료\")\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\n학습 완료! (총 소요시간: {total_time/60:.1f}분)\")\n",
        "        print(f\"   최고 Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "        return history\n",
        "    # 학습 실행\n",
        "    print(\"\\n학습 시작!\\n\")\n",
        "    num_epochs = 20  # 최대 20 에폭 (Early Stopping으로 조기 종료 가능)\n",
        "    history = train_and_validate(\n",
        "        model, train_loader, val_loader, criterion,\n",
        "        optimizer, scheduler, early_stopping, num_epochs\n",
        "    )\n",
        "\n",
        "    experiment_config['actual_epochs'] = len(history['train_loss'])\n",
        "    experiment_config['best_val_accuracy'] = max(history['val_acc']) if history['val_acc'] else 0.0\n",
        "\n",
        "    # 학습 곡선 시각화 (4개 그래프)\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # Loss 곡선\n",
        "    axes[0, 0].plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
        "    axes[0, 0].plot(epochs_range, history['val_loss'], 'r-o', label='Val Loss', linewidth=2)\n",
        "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0, 0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy 곡선\n",
        "    axes[0, 1].plot(epochs_range, history['train_acc'], 'b-o', label='Train Acc', linewidth=2)\n",
        "    axes[0, 1].plot(epochs_range, history['val_acc'], 'r-o', label='Val Acc', linewidth=2)\n",
        "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    axes[0, 1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning Rate 변화\n",
        "    axes[1, 0].plot(epochs_range, history['learning_rates'], 'g-o', linewidth=2)\n",
        "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Learning Rate', fontsize=12)\n",
        "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].set_yscale('log')  # 로그 스케일\n",
        "\n",
        "    # Overfitting 분석\n",
        "    gap = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
        "    axes[1, 1].plot(epochs_range, gap, 'purple', linewidth=2)\n",
        "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    axes[1, 1].fill_between(epochs_range, gap, 0, where=(gap>0), alpha=0.3, color='red', label='Overfitting')\n",
        "    # where= (gap > 0) gap 이 0 보다 클경우\n",
        "    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Accuracy Gap (%)', fontsize=12)\n",
        "    axes[1, 1].set_title('Overfitting Analysis (Train - Val)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('advanced_training_curves.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n학습 곡선 저장: advanced_training_curves.png\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n학습 데이터가 0개이므로 학습 및 모델 관련 섹션을 건너뜁니다.\")\n",
        "    # 임시 history, model, metrics 설정\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rates': []}\n",
        "    model = nn.Linear(1, 1).to(device)\n",
        "    accuracy, f1, roc_auc, pr_auc = 0.0, 0.0, 0.0, 0.0\n",
        "    experiment_config['actual_epochs'] = 0\n",
        "    experiment_config['best_val_accuracy'] = 0.0\n"
      ],
      "metadata": {
        "id": "JxYDY5aiXxVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "QqlO0o5Ngghc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse Frequency Class Weighing\n",
        "# 데이터 불균형 (현재 상황) 클래스 불균형\n",
        "# 정상인 보다 폐렴에 시달리는 환자가 거의 3배 많은 데이터\n",
        "# >> 가중치로 조정\n",
        "# >> 데이터가 적은 클래스 >> 가중치 높게 (중요하니깐)\n",
        "# >> 데이터가 많은 클래스 >> 가중치 낮게 (덜 중요하니깐)\n",
        "# N: 전체 데이터 개수 (total samples)\n",
        "# C: 클래스 (여기서 2개, 정상, 폐렴환자)\n",
        "# N_j : 특정 클래스(j) 데이터 개수 : 정상 폐 데이터, 폐렴환자 폐 데이터\n",
        "\n",
        "# 예) 전체 100명, 클래스 2(정상, 폐렴)\n",
        "# 정상(10명) 폐렴환자(90명)\n",
        "# 정상 100 / (2*10) = 5 (W_정상)\n",
        "# 폐렴환자 100 / (2*90) = 0.55 (W_폐렴)\n",
        "\n",
        "# 전처리 순서\n",
        "# 데이터셋 로드 >> 가중치 계산 (클래스 불균형 고려, 역빈도 계산 후) >> random split\n",
        "# >> (batch_size) 결정 한 후, 데이터로더 >> (**) 학습할 때 loss 함수에 가중치 주입하세요\n",
        "# 역빈도 적용은 희긔해서 중요도가 높은 데이터 (소수 클래스) 손실함수에 가중치(penalty) 부여"
      ],
      "metadata": {
        "id": "zvgS_qhUgmCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 7: 심화 평가 (ROC-AUC, Precision-Recall)\n",
        "\n",
        "# 평가 함수 (확률값 포함)\n",
        "def evaluate_model_advanced(model, test_loader):\n",
        "    \"\"\"\n",
        "    고급 평가 함수 - 확률값 및 상세 메트릭 반환\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    all_probabilities = []  # 확률값 저장\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            # test_dataset은 return_path=True이므로 3개의 요소 반환\n",
        "            # images, labels, img_path\n",
        "            images, labels, _ = batch\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.softmax(outputs, dim=1)  # 확률로 변환\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    return (np.array(all_labels),\n",
        "            np.array(all_predictions),\n",
        "            np.array(all_probabilities))\n",
        "\n",
        "if is_trainable and len(test_dataset) > 0:\n",
        "    # 평가 실행\n",
        "    print(\"\\n테스트 데이터 평가 중...\")\n",
        "    true_labels, pred_labels, pred_probs = evaluate_model_advanced(model, test_loader)\n",
        "\n",
        "    # 기본 메트릭\n",
        "    accuracy = accuracy_score(true_labels, pred_labels) * 100\n",
        "    f1 = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\n테스트 성능:\")\n",
        "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"   F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Confusion Matrix 시각화\n",
        "    # [Image of Confusion Matrix example]\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['NORMAL', 'PNEUMONIA'],\n",
        "                yticklabels=['NORMAL', 'PNEUMONIA'],\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('advanced_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(true_labels, pred_labels,\n",
        "                              target_names=['NORMAL', 'PNEUMONIA'], zero_division=0))\n",
        "\n",
        "    # ROC Curve 및 AUC\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, pred_probs[:, 1])\n",
        "    # pred_probs[:, 1] \":\" 데이터는 다 가져와, 1번(폐렴/양성)일 확률만 사용\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    # >> 데이터불균형 심할 때 (P-R 반비례 관례 Trade-off 관계여서)\n",
        "    # >> 그래프 어떻게 봐요? 면적이 클수록 좋아요 (우측 상단에 붙을 수록)\n",
        "    precision, recall, pr_thresholds = precision_recall_curve(true_labels, pred_probs[:, 1])\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
        "\n",
        "    # ROC & PR Curve 시각화\n",
        "    # [Image of ROC Curve and Precision-Recall Curve example]\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # ROC Curve\n",
        "    axes[0].plot(fpr, tpr, color='darkorange', lw=2,\n",
        "                label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
        "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    axes[0].set_xlim([0.0, 1.0])\n",
        "    axes[0].set_ylim([0.0, 1.05])\n",
        "    axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
        "    axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
        "    axes[0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(loc=\"lower right\")\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    axes[1].plot(recall, precision, color='blue', lw=2,\n",
        "                label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
        "    axes[1].set_xlim([0.0, 1.0])\n",
        "    axes[1].set_ylim([0.0, 1.05])\n",
        "    axes[1].set_xlabel('Recall', fontsize=12)\n",
        "    axes[1].set_ylabel('Precision', fontsize=12)\n",
        "    axes[1].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(loc=\"lower left\")\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\nROC & PR Curves 저장: roc_pr_curves.png\")\n",
        "\n",
        "    experiment_config['test_accuracy'] = float(accuracy)\n",
        "    experiment_config['f1_score'] = float(f1)\n",
        "    experiment_config['roc_auc'] = float(roc_auc)\n",
        "    experiment_config['pr_auc'] = float(pr_auc)\n",
        "\n",
        "else:\n",
        "    print(\"\\n학습이 불가능하거나 테스트 데이터셋이 비어있어 평가를 건너뜁니다.\")\n",
        "    experiment_config['test_accuracy'] = 0.0\n",
        "    experiment_config['f1_score'] = 0.0\n",
        "    experiment_config['roc_auc'] = 0.0\n",
        "    experiment_config['pr_auc'] = 0.0"
      ],
      "metadata": {
        "id": "hC4JuBmJmWqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 8: 고급 Grad-CAM 분석\n",
        "\n",
        "# 학습이 정상적으로 완료되고 테스트 데이터가 있는 경우에만 CAM 분석 수행\n",
        "if is_trainable and len(test_dataset) > 0:\n",
        "\n",
        "    print(\"\\n고급 CAM 기법:\")\n",
        "    print(\"   1. Grad-CAM: 기본 CAM\")\n",
        "    print(\"   2. Grad-CAM++: 개선된 가중치\")\n",
        "    print(\"   3. Score-CAM: 기울기 없이 활성화만 사용\")\n",
        "\n",
        "    # 다양한 CAM 기법 준비\n",
        "    target_layers = [model.layer4[-1]]\n",
        "    grad_cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    grad_cam_plus = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
        "    score_cam = ScoreCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "    cam_methods = {\n",
        "        'Grad-CAM': grad_cam,\n",
        "        'Grad-CAM++': grad_cam_plus,\n",
        "        'Score-CAM': score_cam\n",
        "    }\n",
        "\n",
        "    # 샘플 이미지 선택 (클래스별 2개씩)\n",
        "    def get_sample_images_advanced(test_dataset, num_per_class=2):\n",
        "        \"\"\"각 클래스에서 샘플 추출 (경로 포함)\"\"\"\n",
        "        samples = {'NORMAL': [], 'PNEUMONIA': []}\n",
        "\n",
        "        for idx in range(len(test_dataset)):\n",
        "            # return_path=True로 설정했으므로 3개의 요소 반환\n",
        "            img_tensor, label, img_path = test_dataset[idx]\n",
        "            class_name = 'NORMAL' if label == 0 else 'PNEUMONIA'\n",
        "\n",
        "            if len(samples[class_name]) < num_per_class:\n",
        "                # 원본 이미지 로드\n",
        "                orig_img = Image.open(img_path).convert('RGB')\n",
        "                samples[class_name].append((img_tensor, label, orig_img, img_path))\n",
        "\n",
        "            if all(len(v) >= num_per_class for v in samples.values()):\n",
        "                break\n",
        "\n",
        "        return samples\n",
        "\n",
        "    print(\"\\n샘플 이미지 선택 및 CAM 생성 중...\")\n",
        "    sample_images = get_sample_images_advanced(test_dataset, num_per_class=2)\n",
        "\n",
        "    # CAM 비교 시각화\n",
        "    for class_name, samples in sample_images.items():\n",
        "        print(f\"\\n{class_name} 클래스 분석:\")\n",
        "\n",
        "        for sample_idx, (img_tensor, label, orig_img, img_path) in enumerate(samples):\n",
        "            # 예측\n",
        "            model.eval()\n",
        "            input_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "                pred_prob = torch.softmax(output, dim=1)\n",
        "                pred_class = torch.argmax(pred_prob, dim=1).item()\n",
        "                confidence = pred_prob[0][pred_class].item() * 100\n",
        "\n",
        "            pred_name = 'NORMAL' if pred_class == 0 else 'PNEUMONIA'\n",
        "            print(f\"   샘플 {sample_idx+1}: 예측={pred_name}, 신뢰도={confidence:.1f}%\")\n",
        "\n",
        "            # 원본 이미지 전처리\n",
        "            orig_img_resized = orig_img.resize((224, 224))\n",
        "            rgb_img = np.array(orig_img_resized, dtype=np.float32) / 255.0 # 0~1 범위로 정규화\n",
        "\n",
        "            # 여러 CAM 기법 적용\n",
        "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "            # 원본 이미지\n",
        "            axes[0].imshow(orig_img_resized) # RGB 이미지이므로 cmap='gray' 생략\n",
        "            axes[0].set_title(f'Original\\n{class_name}', fontsize=12, fontweight='bold')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # 각 CAM 기법\n",
        "            for idx, (method_name, cam_method) in enumerate(cam_methods.items()):\n",
        "                targets = [ClassifierOutputTarget(pred_class)]\n",
        "\n",
        "                try:\n",
        "                    # cam_method(input_tensor)가 텐서를 반환하므로 [0, :]로 numpy 배열 추출\n",
        "                    # >> 차원 축소 (1, 244, 244) >> (244,244)\n",
        "                    grayscale_cam = cam_method(input_tensor=input_tensor, targets=targets)[0, :]\n",
        "\n",
        "                    # 오버레이\n",
        "                    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "                    axes[idx+1].imshow(cam_image)\n",
        "                    axes[idx+1].set_title(f'{method_name}', fontsize=12, fontweight='bold')\n",
        "                    axes[idx+1].axis('off')\n",
        "                except Exception as e:\n",
        "                    print(f\"   {method_name} 생성 실패: {e}\")\n",
        "                    axes[idx+1].text(0.5, 0.5, f'{method_name}\\nError',\n",
        "                                   ha='center', va='center')\n",
        "                    axes[idx+1].axis('off')\n",
        "\n",
        "            plt.suptitle(f'Prediction: {pred_name} ({confidence:.1f}%)',\n",
        "                        fontsize=14, fontweight='bold')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'cam_comparison_{class_name}_{sample_idx+1}.png',\n",
        "                       dpi=150, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "    print(\"\\nCAM 비교 결과 저장 완료\")\n",
        "else:\n",
        "    print(\"\\n학습 또는 테스트 데이터셋이 비어있어 CAM 분석을 건너뜁니다.\")"
      ],
      "metadata": {
        "id": "GaESL-sjuDX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 섹션 9: 모델 저장 및 최종 보고서\n",
        "\n",
        "\n",
        "# 모델 저장 (학습이 정상적으로 완료된 경우에만 저장)\n",
        "# model.state_dict() 모델의 파라미터(가중치, 편향)\n",
        "# optimizer.state_dict() 최적화 도구가 가지고 있는 내부 상태값(현재의 모멘텀, lr scheduler)\n",
        "# experiment_config.json 우리가 처음에 설정했던 하이퍼파라미터들(배치 크기, lr, epochs)\n",
        "# history : 학습과정에서 기록된 loss, accuracy 변환 리스트\n",
        "model_save_path = 'best_resnet18_pneumonia.pth'\n",
        "if is_trainable:\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'config': experiment_config,\n",
        "        'history': history,\n",
        "    }, model_save_path)\n",
        "    print(f\"\\n모델 저장 완료: {model_save_path}\")\n",
        "else:\n",
        "    print(\"\\n학습이 진행되지 않아 모델 저장을 건너뜁니다.\")"
      ],
      "metadata": {
        "id": "mmbFYrx3wjer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험 설정 JSON 저장\n",
        "config_save_path = 'experiment_config.json'\n",
        "with open(config_save_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(experiment_config, f, indent=2, ensure_ascii=False)\n",
        "print(f\"실험 설정 저장: {config_save_path}\")"
      ],
      "metadata": {
        "id": "fx-YS7R5xleR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 성능 보고서\n",
        "\n",
        "report = f\"\"\"\n",
        "실험 일시: {experiment_config['date']}\n",
        "디바이스: {experiment_config['device']}\n",
        "\n",
        "[데이터셋]\n",
        "- Train: {experiment_config.get('train_size', 0)}장\n",
        "- Validation: {experiment_config.get('val_size', 0)}장\n",
        "- Test: {experiment_config.get('test_size', 0)}장\n",
        "- 클래스 불균형 비율: {experiment_config.get('class_imbalance_ratio', 0.0):.2f}:1\n",
        "\n",
        "[모델 설정]\n",
        "- 모델: ResNet18 Transfer Learning\n",
        "- 옵티마이저: {experiment_config.get('optimizer', 'N/A')}\n",
        "- Learning Rate: {experiment_config.get('learning_rate', 'N/A')}\n",
        "- Batch Size: {experiment_config.get('batch_size', 'N/A')}\n",
        "- 실제 학습 에폭: {experiment_config.get('actual_epochs', 0)}\n",
        "\n",
        "[성능]\n",
        "- Test Accuracy: {experiment_config.get('test_accuracy', 0.0):.2f}%\n",
        "- F1-Score: {experiment_config.get('f1_score', 0.0):.4f}\n",
        "- ROC-AUC: {experiment_config.get('roc_auc', 0.0):.4f}\n",
        "- PR-AUC: {experiment_config.get('pr_auc', 0.0):.4f}\n",
        "- Best Val Accuracy: {experiment_config.get('best_val_accuracy', 0.0):.2f}%\n",
        "\n",
        "[생성 파일]\n",
        "- advanced_training_curves.png\n",
        "- advanced_confusion_matrix.png\n",
        "- roc_pr_curves.png\n",
        "- cam_comparison_*.png\n",
        "- {model_save_path}\n",
        "- {config_save_path}\n",
        "\"\"\"\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "0jTWtD3dyKxN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}