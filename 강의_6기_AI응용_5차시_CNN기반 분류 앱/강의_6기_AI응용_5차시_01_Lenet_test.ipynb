{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강의_6기_AI응용_5차시_01_Lenet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n1VtvV9B3GmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.9.1+cu130\n",
      "NumPy 버전: 2.2.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23bbbf1bfd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Subset\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"NumPy 버전: {np.__version__}\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:Dev\\rokey\\AI_basic\\trial_class\\project1_251111\\data\n",
      "test_data\n",
      "train_data\n",
      "train_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 폴더\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "folder = Path('C:', 'Dev', 'rokey', 'AI_basic', 'trial_class', 'project1_251111', 'data')\n",
    "\n",
    "train_dir = folder.joinpath('dat', 'train')\n",
    "val_dir = folder.joinpath('dat', 'test')\n",
    "\n",
    "print(folder)\n",
    "for _ in folder.iterdir():\n",
    "    print(_.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, transform_img=None, train=True):\n",
    "        self.name2label = pd.read_csv(data_path.joinpath(\"train_data.csv\"))\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            tr_path = data_path.joinpath(\"train_data\")\n",
    "            self.imgs = list(tr_path.rglob(\"*.png\"))\n",
    "            self.labels = [self.name2label[p.parent.name] for p in self.imgs]\n",
    "        else:\n",
    "            vl_path = data_path.joinpath(\"val_data\")\n",
    "            self.imgs = list(vl_path.rglob(\"*.png\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.imgs[index])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform_img:\n",
    "            img = self.transform_img(img)\n",
    "\n",
    "        if self.train:\n",
    "            if self.transform_la:\n",
    "                label = self.labels[index]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img, self.imgs[index].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.4377, 0.4438, 0.4728)    # 채널별 평균\n",
    "std  = (0.1980, 0.2010, 0.1970)    # 채널별 표준편차\n",
    "\n",
    "train_ten = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "val_ten = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'tr_path' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tr_dataset = \u001b[43mMyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ten\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m vl_dataset = MyDataset(folder, val_ten, train=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mMyDataset.__init__\u001b[39m\u001b[34m(self, data_path, transform_img, train)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mself\u001b[39m.name2label = pd.read_csv(data_path.joinpath(\u001b[33m\"\u001b[39m\u001b[33mtrain_data.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.train = train\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mself\u001b[39m.tr_path = \u001b[43mtr_path\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mself\u001b[39m.vl_path = vl_path\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train:\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'tr_path' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "tr_dataset = MyDataset(folder, train_ten, train=True)\n",
    "vl_dataset = MyDataset(folder, val_ten, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = MyDataset(folder, train_ten, train=True)\n",
    "vl_dataset = MyDataset(folder, val_ten, train=False)\n",
    "\n",
    "tr = DataLoader(tr_dataset, batch_size=128, shuffle=True)\n",
    "vl = DataLoader(vl_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋의 전체 길이 확인 (선택사항)\n",
    "print(f\"전체 데이터 개수: {len(tr_dataset)}\")\n",
    "\n",
    "# 무작위 인덱스 5개 추출\n",
    "indices = random.sample(range(len(tr_dataset)), 5)\n",
    "\n",
    "# 시각화 또는 데이터 확인\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, idx in enumerate(indices):\n",
    "    data = tr_dataset[idx]\n",
    "    \n",
    "    # 데이터가 (이미지, 라벨) 튜플 형태라고 가정\n",
    "    image, label = data \n",
    "    \n",
    "    # 이미지 텐서를 numpy로 변환 (필요한 경우)\n",
    "    if hasattr(image, 'permute'):\n",
    "        image = image.permute(1, 2, 0).numpy() # (C, H, W) -> (H, W, C)\n",
    "        \n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet 클래스를 정의함. nn.Module을 상속받아 PyTorch 신경망 모듈로 만듦.\n",
    "class LeNet(nn.Module):\n",
    "    # 클래스의 인스턴스를 초기화함. 레이어들을 정의함.\n",
    "    def __init__(self):\n",
    "        # 부모 클래스(nn.Module)의 생성자를 호출함.\n",
    "        super(LeNet, self).__init__()\n",
    "        # 첫 번째 합성곱 레이어(cn1)를 정의함.\n",
    "        # 입력 채널 3개(RGB 이미지), 출력 특징 맵 6개, 커널 크기 5x5를 사용함.\n",
    "        self.cn1 = nn.Conv2d(3, 6, 5)\n",
    "        # 두 번째 합성곱 레이어(cn2)를 정의함.\n",
    "        # 입력 채널 6개, 출력 특징 맵 16개, 커널 크기 5x5를 사용함.\n",
    "        self.cn2 = nn.Conv2d(6, 16, 5)\n",
    "        # 첫 번째 완전 연결 레이어(fc1)를 정의함.\n",
    "        # 입력 크기는 16 * 5 * 5 (이전 레이어의 출력 특징 맵 수 * 공간 크기), 출력 크기는 120임.\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # 두 번째 완전 연결 레이어(fc2)를 정의함.\n",
    "        # 입력 120, 출력 84를 사용함.\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 세 번째 완전 연결 레이어(fc3)를 정의함.\n",
    "        # 입력 84, 최종 출력 클래스 수 10개를 사용함.\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    # 데이터가 신경망을 통과하는 순서를 정의함 (순전파).\n",
    "    def forward(self, x):\n",
    "        # cn1을 적용하고 ReLU 활성화 함수를 통과시킴.\n",
    "        x = F.relu(self.cn1(x))\n",
    "        # 2x2 크기의 맥스 풀링을 적용함. 공간 크기를 절반으로 줄임.\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # cn2를 적용하고 ReLU 활성화 함수를 통과시킴.\n",
    "        x = F.relu(self.cn2(x))\n",
    "        # 2x2 크기의 맥스 풀링을 다시 적용함.\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # 데이터를 평탄화(flatten)함. 배치 차원(-1)을 제외한 모든 차원을 하나의 벡터로 만듦.\n",
    "        x = x.view(-1, self.flattened_features(x))\n",
    "        # 첫 번째 완전 연결 레이어와 ReLU를 통과시킴.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 두 번째 완전 연결 레이어와 ReLU를 통과시킴.\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 최종 출력 레이어를 통과시킴.\n",
    "        x = self.fc3(x)\n",
    "        # 최종 결과를 반환함.\n",
    "        return x\n",
    "\n",
    "    # 데이터를 평탄화하기 위해 특징들의 총 개수를 계산하는 헬퍼 함수임.\n",
    "    def flattened_features(self, x): # (batch, C, H, W) -> C*H*W\n",
    "        # 배치 차원(첫 번째 차원)을 제외한 나머지 차원들의 크기를 가져옴.\n",
    "        # -> 이미지 사이즈 확인작업\n",
    "        size = x.size()[1:]\n",
    "        num_feats = 1\n",
    "        # 모든 차원 크기를 곱하여 총 특징 개수를 계산함.\n",
    "        for s in size:\n",
    "            num_feats *= s\n",
    "        # 총 특징 개수를 반환함.\n",
    "        return num_feats\n",
    "\n",
    "# LeNet 클래스의 인스턴스를 생성함.\n",
    "model = LeNet()\n",
    "# 생성된 모델의 구조를 출력함.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습함수\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "checkpoints = folder.joinpath(\"checkpoints\")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, eval 함수\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='훈련')\n",
    "    for i, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=device):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "\n",
    "        tot_loss += loss.item() * y.size(0)\n",
    "        tot_acc  += (out.argmax(1) == y).float().sum().item() # 정답수 누적\n",
    "        tot_cnt  += y.size(0)\n",
    "\n",
    "        pbar.set_postfix({'LR': current_lr})\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt, current_lr\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            with autocast(device_type=device):\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "            tot_acc  += (out.argmax(1) == y).float().sum().item() # 정답수 누적\n",
    "            tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_hist, te_hist, lr_hist = [], [], []\n",
    "te_loss, best_te_loss, patience_counter = 0, 0, 0\n",
    "for ep in range(1, 5):\n",
    "    tr_loss, tr_acc, current_lr = train_one_epoch(model, train_loader, optimizer, criterion) # tr\n",
    "    te_loss, te_acc = evaluate(model, val_loader, criterion) # va\n",
    "\n",
    "    tr_hist.append((tr_loss, tr_acc))\n",
    "    te_hist.append((te_loss, te_acc))\n",
    "    lr_hist.append(current_lr)\n",
    "    print(f\"Epoch {ep}/{EPOCHS} | train /////{tr_acc:.3f}/////{tr_loss:.3f} | test /////{te_acc:.3f}/////{te_loss:.3f}\")\n",
    "    if ep % 5 == 0:\n",
    "        print(f\"Epoch {ep}/{EPOCHS} | train {tr_acc:.3f}/{tr_loss:.3f} | test {te_acc:.3f}/{te_loss:.3f}\")\n",
    "\n",
    "        torch.save(checkpoints.joinpath(f\"ep{ep}.pth\"))\n",
    "        print(f\"Checkpoint saved: {checkpoints.joinpath(f\"ep{ep}.pth\")}\")\n",
    "\n",
    "        if te_loss < best_te_loss:\n",
    "            best_te_loss = te_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= 5:\n",
    "            print(f\"Early stopping at epoch {ep}\")\n",
    "            break\n",
    "\n",
    "print('학습완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPLVx/lqj/1JBDEh8FUsnqk",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
